{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"times\"><font size=\"6pt\"><p style = 'text-align: center;'> BRYN MAWR COLLEGE\n",
    "\n",
    "<font face=\"times\"><font size=\"6pt\"><p style = 'text-align: center;'><b>Computational Methods in the Physical Sciences</b><br/><br/>\n",
    "\n",
    "<p style = 'text-align: center;'><b>Module 5:  Integration</b><br/><br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\nin}{\\noindent}\n",
    "\\newcommand{\\embo}[1]{\\textbf{\\emph{#1}}}\n",
    "\\newcommand{\\vect}{\\mathbf}\n",
    "\\newcommand{\\uvec}[1]{\\hat{\\boldsymbol{#1}}}\n",
    "\\newcommand{\\xhat}{{\\kern 1pt} \\boldsymbol{\\hat{\\textbf{x}}}}\n",
    "\\newcommand{\\yhat}{{\\kern 1pt} \\boldsymbol{\\hat{\\textbf{y}}}}\n",
    "\\newcommand{\\zhat}{{\\kern 1pt} \\boldsymbol{\\hat{\\textbf{z}}}}\n",
    "\\newcommand{\\ehat}{{\\kern 1pt} \\boldsymbol{\\hat{\\textbf{e}}}}\n",
    "\\newcommand{\\rhat}{{\\kern 1pt} \\boldsymbol{\\hat{\\textbf{r}}}}\n",
    "\\newcommand{\\vhat}{{\\kern 1pt} \\boldsymbol{\\hat{\\textbf{v}}}}\n",
    "\\newcommand{\\fhat}{{\\kern 1pt} \\boldsymbol{\\hat{\\upphi}}}\n",
    "\\newcommand{\\rhohat}{{\\kern 1pt} \\boldsymbol{\\hat{\\rho}}}\n",
    "\\newcommand{\\rdot}{\\dot{r}}\n",
    "\\newcommand{\\vr}{\\vect{r}}\n",
    "\\newcommand{\\vrdot}{\\dot{\\vect{r}}}\n",
    "\\newcommand{\\vrddot}{\\ddot{\\vect{r}}}\n",
    "\\newcommand{\\ro}{\\vect{r}_\\mathrm{o}}\n",
    "\\newcommand{\\rod}{\\dot{\\vect{r}}_\\mathrm{o}}\n",
    "\\newcommand{\\rodd}{\\ddot{\\vect{r}}_\\mathrm{o}}\n",
    "\\newcommand{\\VR}{\\vect{R}}\n",
    "\\newcommand{\\vv}{\\vect{v}}\n",
    "\\newcommand{\\vu}{\\vect{u}}\n",
    "\\newcommand{\\ve}{\\vect{e}}\n",
    "\\newcommand{\\vw}{\\vect{w}}\n",
    "\\newcommand{\\wo}{\\omega_{\\mathrm{o}}}\n",
    "\\newcommand{\\omv}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\So}{S_{\\text{o}}}\n",
    "\\newcommand{\\ddt}{\\dfrac{d}{dt}}\n",
    "\\newcommand{\\ppt}{\\dfrac{\\partial}{\\partial t}}\n",
    "\\newcommand{\\LL}{\\mathcal{L}}\n",
    "\\newcommand{\\HH}{\\mathcal{H}}\n",
    "\\newcommand{\\oh}{\\tfrac{1}{2}}\n",
    "\\newcommand{\\pd}[2]{\\dfrac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\grad}{\\boldsymbol{\\nabla}}\n",
    "%\\newcommand{\\cour}[1]{\\fontfamily{courier}\\selectfont{#1}}\n",
    "\\newcommand{\\Am}{\\mathbf{A}}\n",
    "%\\definecolor{mygray}{rgb}{0.9,0.9,0.9}\n",
    "%\\lstset{backgroundcolor=\\color{mygray},language=[],basicstyle=\\ttfamily,basewidth={0.5em,0.35em}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ***Prerequisite modules:*** Module 0; Module 1\n",
    "   \n",
    "   ***Estimated completion time:*** 4-6 hours\n",
    "   \n",
    "   ***Learning objectives:*** Understand the various numerical approximations to the integral, and considerations regarding their use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./Images/integration_by_parts_xkcd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>(Image credit: xkcd.com)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integration, of course, has many applications â€“ computing areas and volumes (and associated quantities, like centers of mass, moments of inertia, etc.), statistical likelihoods, net fields or forces from distributed sources, etc.  While numerical methods can be applied to the integration of functions whose analytic integrals are known, its real strength is its ability to handle the integrals of real data not described by a function, which are not integrable in any other way.  This module will explore several techniques for numerical integration and compare their advantages and disadvantages.$^1$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Scientist Profile</font>\n",
    "\n",
    "**Annie Jane Easley** was born in Birmingham, Alabama in 1933. Despite the inferiority of the segregated schools she attended, Annie's mother told her that she could be anything she wanted to be, but that she would have to work for it, and she encouraged Annie to get a good education.  From the fifth grade through high school she attended a parochial school and was valedictorian of her graduating class.  After graduation she attended Xavier University in New Orleans, then an African-American Roman Catholic University, where she majored in pharmacy for about two years.  In 1955, she read a local newspaper article about twin sisters who worked for the National Advisory Committee for Aeronautics (NACA) as \"computers\" and the next day she applied for a job.  Within two weeks she was hired, and she became one of four African Americans among around 2500 employees.  She began her career with the agency as a Mathematician and Computer Engineer at the NACA Lewis Flight Propulsion Laboratory (which became the NASA Lewis Research Center and, subsequently, the John H. Glenn Research Center) in Cleveland, Ohio.  She continued her education while working for the agency and, in 1977, obtained a BS in Mathematics from Cleveland State University.  Her 34-year career included developing and implementing computer code to analyze alternative power technologies, supporting the Centaur high-energy upper rocket stage, and identifying and studying energy conversion systems and alternative systems to solve energy problems.  Easley's work with the Centaur project provided the foundations for launches of the space shuttle, as well as communication, military, and weather satellites.  Her work also contributed to the 1997 flight to Saturn of the Cassini probe.  She retired in 1989 (some sources say 1991).  Easley was interviewed in 2001 as part of the NASA Johnson Space Center Oral History Program.  The transcript includes material on the history of the Civil Rights Movement, Glenn Research Center, Johnson Space Center, and the contribution of women to space flight.  (This profile adapted from the Wikipedia page on Annie Easley.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './Images/Annie_Easley.jpg', height=10>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.1  The Trapezoidal Rule</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few standard methods for numerical integration, based on concepts you might have learned about in a calculus course.  All of the methods stem from the simple idea that the integral of a function can be depicted graphically as the area under the curve representing the function.   \n",
    "\n",
    "In a calculus course, the area approximation often is depicted in terms of a series of *rectangles* \\[see Fig. 1(a)\\], but this is an inaccurate approach.  A better approximation using *trapezoids* is shown in Fig. 1(b); the approximation can be improved by making the trapezoidal \"slices\" narrower.  The method for computing the area using trapezoids is known, naturally enough, as the **trapezoidal rule**.  To employ it, imagine that we want to integrate a function $f(x)$ over the range from $x = a$ to $x = b$ (where $b > a$) and that that range will be divided into $N$ slices, each of which then will have width $h  = (b - a) / N$.  In this scenario, the $n^\\textrm{th}$ slice will have its left side at $x_{left} = a + (n - 1)h$, and its right side at $x_{right} = a + nh$ (e.g., the first slice, with $n = 1$, has its left side at $x = a$ and its right side at $x = a + h$).  Remembering that the area of a trapezoid with a flat base is its width times the average of the heights of its sides, the area of the $n^\\textsf{th}$ trapezoidal slice would be\n",
    "\n",
    "\\begin{equation}\n",
    "A_n = \\oh h  \\left[ f(x_{left}) + f(x_{right}) \\right] = \\oh h \\left[ f\\left( a + (n-1)h \\right) + f(a+nh) \\right] .  \n",
    "\\end{equation}\n",
    "\n",
    "This expression is the trapezoidal rule.  To get the entire area under our curve of interest (i.e., to get the integral of the function of interest) over the desired range, we just need to sum over all of the trapezoidal areas, as $n$ runs from $1$ to $N$.  The resulting numerical \"integral\" can be written as \n",
    "\n",
    "\\begin{equation}\n",
    "I(f; a,b) = \\oh h \\sum_{n=1}^{N} \\left[ f\\left( a + (n-1)h \\right) + f(a+nh) \\right] .   \\hspace{50pt}  (1) %\\label{trap}\n",
    "\\end{equation}\n",
    "\n",
    "A modified version of Eq. (1), known as the **extended trapezoidal rule**, results from noticing that since each side of a trapezoid is shared between two adjacent trapezoids, except at the endpoints $a$ and $b$, each of the function evaluations in the bracketed expression of Eq. (1) --- except for the ones at the endpoints --- actually appears twice in the overall sum.  Thus, the sum can be written as the following (note that factors of $\\oh$ now accompany only the values of the function at the endpoints $a$ and $b$, and that the upper limit of the sum has changed, so as not to double-count the second side of the last trapezoid):\n",
    "\n",
    "\\begin{equation}\n",
    "I(f; a,b) = h \\left[ \\oh f(a) + \\oh f(b) + \\sum_{n=1}^{N-1} f(a+nh) \\right] .   \\hspace{50pt}  (2)  %\\label{exttrap}\n",
    "\\end{equation}\n",
    "\n",
    "This is the extended trapezoidal rule.  Keep in mind that it is simply Eq. (1) written in a different form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./Images/Rectangle_method.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 1(a): The rectangle method of approximating an integral.</center>\n",
    "<br>\n",
    "<center>(Image credit: Michael Richmond, Rochester Institute of Technology; http://spiff.rit.edu/classes/phys317/lectures/num\\_integ2/num\\_integ2.html )</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./Images/Trapezoidal_method.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 1(b): The trapezoid method of approximating an integral.</center>\n",
    "<br>\n",
    "<center>(Image credit: Michael Richmond, Rochester Institute of Technology; http://spiff.rit.edu/classes/phys317/lectures/num\\_integ2/num\\_integ2.html )</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Breakpoint 1</b></font>: Using Eq. (2), write out the expression for the integral approximation $I$ of a function $f(x)$ based on equally-spaced sample points $x_1 < x_2 < x_3 < x_4 < x_5$ separated by intervals of $h$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.2  Simpson's Method</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While increasing the number of trapezoids can increase the accuracy of the trapezoidal method, that may result in an undesirable increase in computation time.  Fortunately, there exist other approximation methods that can be implemented more efficiently.  These other approaches are based on the idea that the function to be integrated can be approximated not by straight line segments, as in the trapezoidal rule, but by curves.  **Simpson's rule** or **method** implements this approach using *quadratic* curve segments, as depicted in Figure 2 (for four slices, where each of the two quadratic curves spans two adjacent slices; the areas under the quadratics are shaded).   \n",
    "\n",
    "To understand this method, first consider a very simple case, in which we sample the function $f(x)$ that we want to integrate at only three points: $x = -h$, $x = 0$, and $x = h$.  In fitting a quadratic expression, $Ax^2 + Bx + C$, to our function $f(x)$, we require that the quadratic curve pass through the function's values at the three points, which leads to\n",
    "\n",
    "\\begin{equation}\n",
    "f(-h) = A (-h)^2 + B (-h) + C, \\hspace{30pt} f(0) = C, \\hspace{30pt} f(h) = Ah^2 + Bh + C\n",
    "\\end{equation}\n",
    "\n",
    "These three equations can be solved for the three undetermined coefficients, giving\n",
    "\n",
    "\\begin{equation}\n",
    "A = \\dfrac{1}{h^2} \\left[ \\oh f(-h) - f(0) + \\oh f(h) \\right], \\hspace{30pt} B = \\dfrac{1}{2h} \\left[ f(h) - f(-h) \\right] , \\hspace{30pt} C = f(0) .  \\hspace{50pt}  (3)   %\\label{simpsoncoeffs}\n",
    "\\end{equation}\n",
    "\n",
    "The area (i.e., integral) corresponding to this quadratic approximation to $f(x)$ then is:\n",
    "\n",
    "\\begin{equation}\n",
    "Area = \\int_{-h}^h \\left( Ax^2 + Bx + C \\right) \\, dx = \\left[ \\dfrac{1}{3} Ax^3 + \\dfrac{1}{3} Bx^2 + Cx \\right] \\Biggr|_{-h}^{+h} = \\dfrac{2}{3} Ah^3 + 2Ch = \\dfrac{1}{3} h \\left[ f(-h) + 4f(0) + f(h) \\right]   \\hspace{30pt}  (4)  %\\label{simpson}\n",
    "\\end{equation}\n",
    "\n",
    "This is the result known as Simpson's rule.  It represents the approximate integral of a function that has been divided into just two \"slices,\" each of width $h$: one slice extending from $x = -h$ to $x = 0$, and another from $x = 0$ to $x = h$ (or, in the figure, the ranges spanned by  \"Quadratic 1\" and \"Quadratic 2\").  In the usual case that the function is to be approximated by more than one quadratic curve for greater accuracy, we imagine dividing the $x$-range into many slices and then the areas in *pairs* of adjacent slices are approximated by an expression of the form in Eq. (4).  (Note that the total number of slices must be even for this method to work.  As in the trapezoidal rule, there are two sample points per slice, one at each boundary of the slice.)  For example, consider a section of a curve broken up into six slices, with the boundaries of the half-slices at $x = a, x_1, x_2, x_3, x_4, x_5, b$, with the separation between consecutive points being $h$ (so $x_1 = a + h$, $x_2 = a + 2h$, ..., and therefore $x_n = a + nh$ in general).  These six slices can be grouped into three pairs of slices, and adding the areas for those pairs according to Eq. (4) we would obtain\n",
    "\n",
    "\\begin{align}\n",
    "\\textit{Area} & = \\dfrac{1}{3} h \\left( [f(a) + 4f(x_1) + f(x_2)] + [f(x_2) + 4f(x_3) + f(x_4)] + [f(x_4) + 4f(x_5) + f(b)] \\right) \\\\\n",
    "& = \\dfrac{1}{3} h \\left[ f(a) + 4f(x_1) + 2f(x_2) + 4f(x_3) + 2f(x_4) + 4f(x_5) + f(b) \\right] \\\\\n",
    "& = \\dfrac{1}{3} h \\left[ f(a) + 4f(a+h) + 2f(a+2h) + 4f(a+3h) + 2f(a+4h) + 4f(a+5h) + f(b) \\right]\n",
    "\\end{align}\n",
    "\n",
    "We can see a pattern here, which is encapsulated in the general formula below for the Simpson's rule integral, $I(f; a, b)$, of a function $f(x)$ over the range $x = a$ to $x = b$ based on $N$ slices:\n",
    "\n",
    "\\begin{equation}\n",
    "I(f; a, b) = \\dfrac{1}{3} \\, h \\left[ f(a) +  f(b) + 4 \\! \\sum_{\\substack{n \\textrm{ odd} \\\\ 1 \\dots N-1}} f(a+nh) + 2 \\! \\sum_{\\substack{n \\textrm{ even} \\\\ 2 \\dots N-2}} f(a+nh) \\right] .   \\hspace{50pt}  (5)  %\\label{extsimpson}\n",
    "\\end{equation}\n",
    "\n",
    "This sometimes is known as the **extended Simpson's rule**, in analogy with Eq. (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./Images/fig5-2.png\" width=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Figure 2: Simpson's method of approximating an integral.</center>\n",
    "<br>\n",
    "<center>(Image credit: *Computational Physics*, M. Newman)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Breakpoint 2</b></font>: Using Eq. (5), write out the expression for the integral approximation $I$ of a function $f(x)$ based on the same sample points as in *Breakpoint 1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.3  Choosing the Number of Steps, $N$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining an appropriate number of steps (i.e., slices) to use in an integration is a balancing act: the larger $N$, the more accurate the calculation, but the more time it takes.  A careful, lengthy analysis of the formulas for the trapezoidal rule and Simpson's rule shows that the approximation errors associated with those methods are of orders \n",
    "\n",
    "$$\\epsilon_{trap} \\sim h^2 \\textsf{    (more precisely, } \\epsilon = \\tfrac{1}{12} h^2 \\left[ f'(a) - f'(b) \\right]) $$\n",
    "and \n",
    "$$\\epsilon_{Simpson} \\sim h^4  \\textsf{    (more precisely, } \\epsilon = \\tfrac{1}{90} h^4 \\left[ f'''(a) - f'''(b) \\right]),$$ \n",
    "\n",
    "respectively.$^4$  Thus, the smaller $h$ is made (i.e., the bigger $N$ is made), the greater the accuracy of the two methods, with the Simpson's rule approach being significantly more accurate as $h$ shrinks (i.e., as $N$ grows).\n",
    "\n",
    "When the derivatives in the expressions for $\\epsilon$ aren't available analytically, the errors can be estimated using a numerical approach.  Imagine comparing the approximations from the trapezoidal rule using two different values of $h$, call them $h_1$ and $h_2$, and let $h_2 = \\oh h_1$.  Let the true value of the integral be denoted $I$, the approximate result using $h_1$ be denoted $I_1$, and the approximate result using $h_2$ be denoted $I_2$.  Then, since the error in the trapezoidal approach is ${\\sim}h^2$, we can express the errors $\\epsilon_1$ and $\\epsilon_2$ in the two approximations as\n",
    "\n",
    "$$I = I_1 + \\epsilon_1 = I_1 + ch_1^2 \\hspace{10pt} \\textsf{and} \\hspace{10pt} I = I_2 + \\epsilon_2 = I_2 + ch_2^2 = I_2 + \\tfrac{1}{4} ch_1^2,$$\n",
    "\n",
    "where $c$ is some constant.  If we equate the right-hand sides of the two expressions for $I$, we get $I_1 + ch_1^2 = I_2 + \\tfrac{1}{4} ch_1^2,$ and then the difference between the two approximations is $I_2 - I_1 = \\tfrac{3}{4} ch_1^2 = 3ch_2^2$.  Thus, an estimate of the error in the second approximation of the trapezoidal rule is\n",
    "\n",
    "\\begin{equation} \n",
    "\\epsilon_2 = ch_2^2 = \\tfrac{1}{3} (I_2 - I_1) ,\n",
    "\\end{equation}\n",
    "\n",
    "of which we're interested only in the absolute value.  Now imagine continuing to double $N$, thereby halving $h$, and getting a new approximation to the integral with each doubling.  Doing this, and noting the previous expression, we would have for the error in the $k^\\textrm{th}$ approximations of the trapezoidal and Simpson methods\n",
    "\n",
    "\\begin{align} \n",
    "\\epsilon_k \\equiv ch_k^2 = \\tfrac{1}{3} (I_k - I_{k-1}) ,  \\hspace{50pt} & \\textsf{Trapezoidal rule error;}  \\hspace{50pt}  (6)  \\\\  %\\label{traperror}   \n",
    "\\epsilon_k \\equiv c' h_k^4 = \\tfrac{1}{15} (I_k - I_{k-1}) ,  \\hspace{50pt} & \\textsf{Simpson's rule error;}  \\hspace{57pt}  (7) %\\label{simpsonerror}\n",
    "\\end{align}\n",
    "\n",
    "where $c'$ is another constant (different from $c$, in general) appropriate for Simpson's rule.  (The factor of $\\tfrac{1}{15}$ for Simpson's rule appears because that rule depends on $h^4$ rather than $h^2$, so every doubling introduces a factor of $\\tfrac{1}{16}$ rather than $\\tfrac{1}{4}$; the factor $\\tfrac{1}{15}$ falls out when two successive approximations are subtracted.)  \n",
    "\n",
    "The beauty of these expressions is that they tell us the error in our approximation based not on the *exact* integral (which we don't know, or we wouldn't be bothering with a computation!), but just on the values of two successive *computations* (the $I_{k-1}$ and $I_k$ approximations).  The idea, then, is to start with some relatively small value of $N$, maybe $N_1 = 10$, evaluate the integral, then double $N$ -- so that $N_2 = 2N_1 = 20$, and therefore $h$ is halved -- and evaluate the integral again.  If the error given by Eq. (6) [or (7)] is small enough to meet the user's needs, then the job is done.  If not, then $N$ is doubled again.  This process of changing some parameter until the desired integration accuracy is obtained is called **adaptive integration**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Breakpoint 3</b></font>: Consider the case that we double $N$ in every iteration of the trapezoidal rule approximation to the integral of some function (so that $h_2 = \\oh h_1$, $h_3 = \\oh h_2$, etc.).  (a) Suppose that the first two approximation results are $I_1 = 5.0 \\times 10^{-6}$ and $I_2 = 1.0 \\times 10^{-6}$.  Determine $I_3 - I_2$ and $I_4 - I_3$.  (b) If we want the error in our approximation to be less than $4.0 \\times 10^{-7}$, what is the lowest iteration after which we may stop?  Briefly explain your answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice feature of this $N$-doubling approach is that after the first calculation of the integral, subsequent computations can be performed just by adding a new sum to the previous result.  Since doubling $N$ amounts to including additional function sample points half way between the ones used in the previous calculation, the sum in Eq. (1) (in the case that we're using the trapezoidal rule) just has to include the new points.  Such additional points must be included every time $N$ is doubled; ultimately, the following result for the $k^\\textsf{th}$ estimate of the integral is found:\n",
    "\n",
    "\\begin{equation} \n",
    "I_k = \\oh I_{k-1} + h_k \\hspace{-5pt} \\sum_{\\substack{n \\, \\textsf{odd} \\\\ 1 \\dots N_k - 1}} \\hspace{-5pt}  f( a + nh_k) ,\n",
    "\\end{equation}\n",
    "\n",
    "where $h_k = h_1 / \\, 2^{k-1}$ is the slice width in the $k^\\textsf{th}$ approximation in terms of the original slice width $h_1$.  A key consequence of this result is that it turns out to take only about half as much computation to obtain $I_k$ once you have computed the preceding approximations -- $I_1, I_2, \\dots , I_{k-1}$ -- as it does to calculate it directly using the trapezoidal rule.  Thus, this adaptive integration method guarantees the desired accuracy in the result (assuming that accuracy does not exceed the rounding error of the computer) without costing much in the way of computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.4  Higher-order Methods</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no reason why we have to stop with the quadratic fitting approach of Simpson's rule --- we could use higher-order polynomials which might give more accurate results.  The *general form* of the extended trapezoidal rule [Eq. (1)], Simpson's method [Eq. (5)], and the higher-order approaches is\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_a^b f(x) \\, dx \\simeq \\sum_{k=1}^N w_k f(x_k),\n",
    "\\end{equation}\n",
    "\n",
    "where the $x_k$ are sample points where the function is evaluated and the $w_k$ are **weights**.  Inspection of Eq. (1) shows that, in the case of the trapezoidal rule, the $w_k$ for the endpoints are $h/2$ while all of the others are $h$; for Simpson's rule, Eq. (5) reveals that the $w_k$ are $h/3$ for the end points, and the others alternate between $4h/3$ and $2h/3$.  These findings, together with the weights for integral approximations based on a cubic polynomial fit, are collected in Table 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:60%\">\n",
    " <caption><font size=\"3\">Table 1: Weights of terms in higher-order approximations of the integral</font></caption>\n",
    " <tr>\n",
    "   <th>$\\textrm{Degree}$</th>\n",
    "   <th>$\\textrm{Type of Polynomial}$</th>\n",
    "   <th>$\\textrm{Weights (all multiplied by $h$)}$</th>\n",
    " </tr>\n",
    " <tr>\n",
    "   <td align=\"center\">$1$</td>\n",
    "   <td align=\"center\">$\\textrm{Linear}$</td>\n",
    "   <td align=\"center\">$\\oh, 1, 1, \\dots, 1, \\oh$</td>\n",
    " </tr>\n",
    " <tr>\n",
    "   <td align=\"center\">$2$</td>\n",
    "   <td align=\"center\">$\\textrm{Quadratic}$</td>\n",
    "   <td align=\"center\">$\\tfrac{1}{3}, \\tfrac{4}{3}, \\tfrac{2}{3}, \\tfrac{4}{3}, \\tfrac{2}{3}, \\dots, \\tfrac{1}{3}$</td>\n",
    " </tr>\n",
    " <tr>\n",
    "   <td align=\"center\">$3$</td>\n",
    "   <td align=\"center\">$\\textrm{Cubic}$</td>\n",
    "   <td align=\"center\">$\\tfrac{3}{8}, \\tfrac{9}{8}, \\tfrac{9}{8}, \\tfrac{3}{4}, \\tfrac{9}{8}, \\tfrac{9}{8}, \\tfrac{3}{4}, \\dots, \\tfrac{9}{8}, \\tfrac{3}{8}$</td>\n",
    " </tr>\n",
    "</table> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher-order integration methods of this type are known as **Newton-Cotes formulas**, which can be implemented for any order polynomial. \n",
    "\n",
    "Note that the trapezoidal rule, which interpolates linearly between the sample points in each slice, would give an *exact* result if the function being integrated were piecewise-linear (i.e., made exclusively of connected straight line segments); similarly, Simpson's rule, which interpolates quadratically between sample points, would give an exact answer for a piecewise-quadratic function.  More generally, we could exactly fit and integrate a function made of connected segments of polynomial degree $N$ using a method that interpolates between sample points using a polynomial of the same degree.  (A special case of this would be a function that, over the entire range of interest, is a polynomial of degree $N - 1$: it could be fit exactly using a total of $N$ sample points.)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.5  Gaussian Quadrature</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial fitting methods discussed above all use equally-spaced points at which to sample the function to be integrated.  Equal spacing has the advantages that it's easy to code, and it's straightforward to add new sample points midway between the old ones.  However, it turns out that by allowing the sample points to be *unequally* spaced, much more accurate algorithms can be designed.  The basic idea is that by allowing the positions of the $N$ sample points to be adjustable, we introduce an additional $N$ \"degrees of freedom\" into the problem --- these act essentially as additional \"knobs\" that can be changed to adjust the fit.  Using $N$ sample points with adjustable positions, we could *exactly* fit a function of polynomial degree up to $2N - 1$.  A very powerful integration method that uses this idea is **Gaussian quadrature**.  The derivation of the appropriate weights and sample point positions is rather lengthy, so it will be omitted.$^2$  The results are:\n",
    "\n",
    "* For integration with $N$ sample points $x_k$, they should be chosen at $x_k = \\oh (b - a) x_k' + \\oh (b + a)$, where the $x_k'$ are the zeros of the $N^\\textrm{th}$ Legendre polynomial, $P_N(x)$. \n",
    "\n",
    "* The corresponding weights are $w_k = \\dfrac{1}{2} (b - a) \\left[ \\dfrac{2}{1-x^2} \\left( \\dfrac{dP_N}{dx} \\right)^{-1} \\right]_{x = x_k}$.\n",
    "\n",
    "Legendre polynomials can be computed using **recurrence relations**, which express a polynomial of some order in terms of one or more polynomials of lower order.  Thus, from the lowest-order polynomials the higher-order ones can be generated.$^3$  \n",
    "\n",
    "Gaussian quadrature is a bit tricky to code, but most numerical analysis function libraries include at least one function that performs such integration.  In Python, the `scipy.integrate` package contains several such functions, including `quadrature` (for a description and a list of similar functions, see  http://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quadrature.html.  For this course, we will use a function adapted from *Computational Physics*, by M. Newman.  The notebook containing the function is called `Gaussian_Quadrature.ipynb` (the function itself is called `gaussQuad`) and it should be available together with the posted modules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.6  Comparison of Integration Methods</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other sophisticated integration methods are known, e.g. **Romberg integration** (based on the trapezoidal rule), but those methods will not be discussed in any detail here.  We merely provide a brief summary of the advantages and disadvantages of various methods:\n",
    "\n",
    "*Trapezoidal rule*: Easy to program and runs quickly, but not very accurate.  Requires equally spaced sample points.  A good choice for noisy functions or those that vary widely.\n",
    "\n",
    "*Simpson's rule*: Also easy to program and also requires equally spaced sample points.  More accurate than trapezoidal rule with the same number of points, but not as good with noisy or otherwise non-smooth functions.\n",
    "\n",
    "*Romberg integration*: Gives very accurate results with a minimum number of sample points, but therefore is sensitive to noisy functions.  Also naturally provides error estimates that can be used to decide when to stop the computation.\n",
    "\n",
    "*Gaussian quadrature*: Gives potentially most accurate results with a minimum number of sample points, but requires them to be unequally spaced.  Therefore, may not be appropriate for laboratory data based on regular increments of some parameter (e.g., time, angle, position).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.7  Integration Over Infinite Ranges</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many problems of physical interest involve integrals over infinite ranges, which can't be done numerically since it would require an infinite number of sample points.  The trick in these cases is to perform a change of variables that makes the integration range finite.  For example, for integration over the semi-infinite range $x = 0 \\rightarrow \\infty$, the standard change is to define a new variable $z \\equiv \\dfrac{x}{1+x}$, so $x = \\dfrac{z}{1-z}$.  With this choice, $x \\rightarrow \\infty$ corresponds to $z \\rightarrow 1$ (while $x = 0$ corresponds to $z = 0$).  Further, we find that $dx = \\dfrac{dz}{(1-z)^2}$, and so \n",
    "\n",
    "\\begin{equation}\n",
    "\\int_0^\\infty f(x) \\, dx \\; \\rightarrow \\; \\int_{0}^1 \\dfrac{1}{(1-z)^2} \\; \\, f\\left( \\dfrac{z}{1-z} \\right) dz.  \\hspace{50pt}  (8)  %\\label{finiterange}\n",
    "\\end{equation}\n",
    "\n",
    "This integral, which now extends over a finite range, can be performed using any of the previously discussed numerical methods.  \n",
    "\n",
    "An integral over the range $-\\infty \\rightarrow +\\infty$ can be split in half, and each half treated as in the semi-infinite case.  An integral from some nonzero $a$ to $\\infty$ can be done by first defining a new variable $y = x - a$, which vanishes when $x$ is at the lower bound $a$, and then setting $z = y/(1+y)$ as above (so that $x \\rightarrow \\infty$ corresponds to $y \\rightarrow 1$).  In some cases, these standard transformations might not work well, and you would have to try variations on these themes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Breakpoint 4</b></font>: Statistical mechanics tells us that the mean absolute value of the $x$-component (or $y$- or $z$-component) of the velocity of a molecule (of mass $m$) in a uniform gas at temperature $T$ is given by the integral\n",
    "\n",
    "\\begin{equation}\n",
    "\\left< \\left| v_x \\right|\\right> = \\sqrt{\\dfrac{2m}{\\pi kT}} \\int_0^\\infty v_x \\, e^{-mv_x^2/2kT} \\, dv_x \n",
    "\\end{equation}\n",
    "\n",
    "(where $k$ is Boltzmann's constant).  Rewrite this as an integral over the range $0 \\rightarrow 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">5.8  Multiple Integrals</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrals over more than one variable can be performed using generalizations of the techniques already seen.  For example, for a generic integral over two variables (where the first integral, over the range $c \\rightarrow d$, corresponds to the variable $y$, and the second integral, over the range $a \\rightarrow b$, corresponds to $x$),\n",
    "\n",
    "\\begin{equation}\n",
    "I = \\int_c^d \\int_a^b f(x, y) \\, dx \\, dy ,\n",
    "\\end{equation}\n",
    "\n",
    "we can define a function $F(y)$ as\n",
    "\n",
    "\\begin{equation}\n",
    "F(y) =  \\int_a^b f(x, y) \\, dx ,\n",
    "\\end{equation}\n",
    "\n",
    "so then\n",
    "\n",
    "\\begin{equation}\n",
    "I =  \\int_c^d F(y) \\, dy .\n",
    "\\end{equation}\n",
    "\n",
    "Thus, the original integral over two variables has been converted into two integrals, each over just one variable, which we've seen how to do.  Similarly, using the Gaussian quadrature approach, we can write\n",
    "\n",
    "\\begin{equation}\n",
    "F(y) \\simeq  \\sum_{i=1}^N w_i \\, f(x_i, y) , \\hspace{10mm} \\textrm{and then} \\hspace{10mm}  I \\simeq \\sum_{j=1}^N w_j F(y_j) .\n",
    "\\end{equation}\n",
    "\n",
    "Taken together, these two expressions give the **Gauss-Legendre product formula**:\n",
    "\n",
    "\\begin{equation}\n",
    "I \\simeq \\sum_{i=1}^N \\sum_{j=1}^N w_i w_j \\, f(x_i, y_j) .\n",
    "\\end{equation}\n",
    "\n",
    "It turns out that in more than one dimension (i.e., in Gaussian quadrature involving more than one variable) the best choice of sample point locations ($x_i, y_j$, etc.) is not known.  One approach is to choose the points randomly, which leads to Monte Carlo integration, to be discussed in a later Module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">**Recap**</font>\n",
    "\n",
    "* In the case of one variable, all of the numerical integration methods involve computing and adding up the areas of small \"slices\" within the desired range of integration.  The various methods differ only in the functions (linear, quadratic, etc.) they use to approximate the function of interest within the slices.  \n",
    "<br>\n",
    "\n",
    "* The different integration methods involve tradeoffs between speed, accuracy, the ability to deal with noisy data, and flexibility in choosing sample points.  \n",
    "<br>\n",
    "\n",
    "* Integrals over infinite ranges or  multiple variables can be performed using fairly straightforward modifications of the approaches for the integral of a single variable over a finite range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">**Reflection Prompts**</font>\n",
    "\n",
    "These questions are intended to help you think about what you learned from this module and how it might be useful to you in the future.  You are strongly encouraged to answer them before moving on to the next module.\n",
    "\n",
    "*  Which components of this module did you find you were easily able to work through, and why do you think they were especially easy for you? \n",
    "\n",
    "*  Which components of this module did you find more difficult to work through, and why do you think they were challenging?\n",
    "\n",
    "*  When you got stuck, what did you do to get unstuck?  Could this or similar actions be helpful if you get stuck in future work?\n",
    "\n",
    "*  What do you understand more deeply about this material?\n",
    "\n",
    "*  What questions or uncertainties remain for you regarding this material?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Exercises</font>\n",
    "\n",
    "<u>**Exercise \\#1**</u>  \n",
    "Suppose we want to fit a function $f(x)$ at the four points $x = -\\tfrac{3}{2} h, -\\tfrac{1}{2} h, \\tfrac{1}{2} h, \\tfrac{3}{2} h$ using a cubic polynomial of the form $Ax^3 + Bx^2 + Cx + D$.  Determine the expressions analogous to those in Eq. (3) for the parameters $A, B, C$, and $D$ in this case.  \n",
    "<br>\n",
    "\n",
    "<u>**Exercise \\#2**</u>  \n",
    "Write a Python function to implement the trapezoidal rule of Eq. (1).  Your function should take as arguments: the name of the function to be integrated, the two bounds of integration, and the number of \"slices\" $N$ to use. (a) Test it on the function $f_1(x) = \\sin^2(x)$ over the range ($0, 2\\pi$), using $N = 10$ and $N = 100$.  (b) Also test it on $f_2(x) = x^4 - 2x + 1$ over the range ($0, 2$) with $N = 10$ and $N = 100$.  (c) For either function, is there a difference in the results for the two $N$ values?  \n",
    "<br>\n",
    "\n",
    "<u>**Exercise \\#3**</u>  \n",
    "Modify the Python function you used in Exercise \\#2 to create a new function that implements the *extended* trapezoidal rule.  Test it on function $f_2$ of Exercise \\#2 part (b) using the same parameters, and compare the results from the two approaches.  Also compare with the expected value by computing the integral analytically (i.e., with paper and pencil).  How large must $N$ be made so that the error between your computed value and the analytical value is less than $0.1%$ of the latter?  \n",
    "<br>\n",
    "\n",
    "<u>**Exercise \\#4**</u>  \n",
    "Write or modify a Python function to implement the extended Simpson's rule, Eq. (5), and test it on the same function as in Exercise \\#2 part (b), using $N = 10$.  (Make sure to test whether the input value for $N$ is even.)  What is the percentage error in the result (relative to the analytical answer)?  How does that compare with the error (for the same $N$) using the trapezoidal method?  Hint: syntax for a `for` loop that steps by $2$ over even values is `for n in range(2,N,2)`.  \n",
    "<br>\n",
    "\n",
    "<u>**Exercise \\#5**</u>  \n",
    "Use the `Gaussian_Quadrature` notebook to integrate the functions of Exercise \\#2.  (To run code from one notebook in another, that code must be by itself in the first notebook, and both notebooks must be in the same directory.  In the second notebook, in a code cell type `%run Notebook_name.ipynb`.)  You don't have to understand how the Gaussian quadrature code works (it's not easy).  For the function in part (b) of Exercise \\#2, determine analytically the smallest $N$ value that should produce an exact answer.  Try it out.  For the function in part (a), write a loop that performs the integral for $N$ values from $1$ to $10$, and also compute it for $N = 100$.  What do you conclude about the accuracy of Gaussian quadrature as applied to a function like $\\sin^2(x)$?  Why might this be the case?  \n",
    "<br>\n",
    "\n",
    "<u>**Mastery Exercise \\#1**</u>  \n",
    "The Planck theory of radiation states that a blackbody at temperature $T$ radiates thermal energy in the frequency range $\\omega$ to $\\omega + d\\omega$ at the rate $I(\\omega) d\\omega$ per unit area, where $$I(\\omega) = \\dfrac{\\hbar}{4 \\pi^2 c^2} \\dfrac{\\omega^3}{e^{\\hbar \\omega / kT} - 1}.$$  \n",
    "\n",
    "(That is, $I(\\omega) d\\omega$ is the power radiated per unit area in the small frequency interval $d\\omega$.)  Here, $\\hbar$ is Planck's constant divided by $2\\pi$, $c$ is the speed of light, and $k$ is Boltzmann's constant. }  \n",
    "\t\n",
    "(a) By a change of variables, show that the total power per unit area radiated is \n",
    "\n",
    "$$W = \\dfrac{k^4 T^4}{4 \\pi^2 c^2 \\hbar^3} \\int_0^\\infty \\dfrac{x^3}{e^x - 1} \\, dx .$$ \n",
    "\t\n",
    "(b) Write a program to evaluate this integral.  Discuss what method you used and how accurate you think your answer is. \n",
    "\t\n",
    "(c)  Use your result in (b) to compute a value for the Stefan-Boltzmann constant $\\sigma$, which appears in Stefan's law, $W = \\sigma T^4$.  How close is your result to the accepted value?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3pt\">**Breakpoint Answers**</font>\n",
    "\n",
    "**Breakpoint 1**   \n",
    "From Eq. (2), with $a = x_1$, $b = x_5$, $x_2 = x_1 + h$, $x_3 = x_1 + 2h$, and $x_4 = x_1 + 3h$, we have\n",
    "\n",
    "$$I(f; x_1, x_5) = h \\left[ \\oh f(x_1) + \\oh f(x_4) + f(x_2) + f(x_3) + f(x_4) \\right].$$ \n",
    "\n",
    "\n",
    "**Breakpoint 2**  \n",
    "From Eq. (5), with the same sample points as above, we have \n",
    "\n",
    "$$I(f; x_1, x_5) = \\tfrac{1}{3} h \\left[ f(x_1) + f(x_5) + 4 f(x_2) + 2 f(x_3) + 4 f(x_4) \\right].$$\n",
    "\n",
    "\n",
    "**Breakpoint 3**  \n",
    "(a) We know that $I_2 - I_1 = 4.0 \\times 10^{-6} = c h_2^2$, so then\n",
    "\n",
    "\\begin{align*}\n",
    "I_3 - I_2 & = c h_3^2 = \\tfrac{1}{4} c h_2^2 = 1.0 \\times 10^{-6}, \\\\\n",
    "I_4 - I_3 & = c h_4^2 = \\tfrac{1}{4} c h_3^2 = 2.5 \\times 10^{-7}.\n",
    "\\end{align*}\n",
    "\n",
    "(b) Since we want the error to be less than $4.0 \\times 10^{-7}$, and the error after the $k^{\\textrm{th}}$ iteration is $\\epsilon_k = \\tfrac{1}{3} (I_k - I_{k-1})$, then we can stop after the *third* iteration, since $\\epsilon_3 = \\tfrac{1}{3} (I_3 - I_2) = 3.33 \\times 10^{-7}$, which is less than the desired error.  \n",
    "<br>\n",
    "\n",
    "\n",
    "**Breakpoint 4**  \n",
    "Define a new variable $\\beta = \\dfrac{v_x}{1 + v_x}$, so $v_x = \\dfrac{\\beta}{1-\\beta}$.  Then substituting $\\beta$'s for $z$'s in Eq. (8), with $f$ being the integrand given in the *Breakpoint*, the integral becomes \n",
    "$$\\left<|v_x|\\right> = \\sqrt{\\dfrac{2m}{\\pi kT}} \\int_0^1 \\dfrac{1}{(1 - \\beta)^2} \\, \\left( \\dfrac{\\beta}{1-\\beta} \\right) \\exp\\left[ -\\dfrac{m}{2kT} \\left( \\dfrac{\\beta}{1- \\beta} \\right)^2 \\right] \\, d\\beta .$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "$^1$ This module adapted from *Computational Physics* by Mark Newman.\n",
    "\n",
    "$^2$ See *Computational Physics*, section 5.6, for details.  \n",
    "\n",
    "$^3$ The Legendre polynomials may be familiar from an advanced electromagnetism course, where they are used to express the electric potential at some point $\\vect{r}$ (relative to the origin) due to an electric charge $q$ at another point $\\vect{r}_q$. \n",
    "\n",
    "$^4$ See Ch. 5 of *Computational Physics*.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
