{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=\"times\"><font size=\"6pt\"><p style = 'text-align: center;'> BRYN MAWR COLLEGE\n",
    "\n",
    "<font size=\"6pt\"><p style = 'text-align: center;'><b><font face=\"times\">Computational Methods in the Physical Sciences</b><br/><br/>\n",
    "\n",
    "<p style = 'text-align: center;'><b><font face=\"times\">Module 16:  Machine Learning</b><br/><br/>\n",
    "\n",
    "<p style = 'text-align: center;'><font size=\"3pt\"><font face=\"times\"> Adapted from </br> \n",
    "<a href=\"https://neuralnetworksanddeeplearning.com/index.html\"/><em>Neural Networks and Deep Learning</em></a>, Michael Nielsen</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***Prerequisite modules***: Module 1\n",
    "\n",
    "***Estimated completion time***: 6-8 hours  \n",
    "\n",
    "***Learning objectives***: Learn the basic structure of neural networks, and become familiar with the main Python libraries for working with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Images/neural_network_xkcd.png\" width=\"250\" height=\"210\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>(Image credit: https://xkcd.com/2173)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = \"blue\"> Introduction </font>\n",
    "\n",
    "Artificial intelligence (AI), machine learning (ML), and deep learning are hot \"buzz words\" these days, but what do they mean?  It's not clear that there are universally agreed-upon definitions for these terms, but according to the Columbia University engineering department (https://ai.engineering.columbia.edu/ai-vs-machine-learning/), \"...artificial intelligence refers to the general ability of computers to emulate human thought and perform tasks in real-world environments, while machine learning refers to the technologies and algorithms that enable systems to identify patterns, make decisions, and improve themselves through experience and data.\"  That is, machine learning learning systems can learn on their own, without being programmed explicitly to do so.  Finally, \"Deep learning, an advanced method of machine learning, goes a step further. Deep learning models use large neural networks — networks that function like a human brain to logically analyze data — to learn complex patterns and make predictions independent of human input.\"\n",
    "\n",
    "Machine learning systems are effective at a number of tasks (from https://learn.microsoft.com/en-us/dotnet/machine-learning/resources/tasks): ***classification*** of examples into two or more categories; ***regression***, in which some characteristic of a set of data is predicted from other characteristics; ***clustering***, or grouping similar entities together; ***anomaly detection***, finding outliers among data or events; ***ranking***, or sorting of data by relevance, e.g. Google search results; ***recommendations***, e.g. of Amazon items based on previous purchases; ***forecasting***, e.g. of stock values from previous performance; ***object detection*** in images; and others.\n",
    "\n",
    "This module will focus on artificial neural networks, which are able to perform processing tasks that are very difficult using traditional programming methods.  This module will present the basics of neural networks, introduce the main Python libraries (\"PyTorch,\" \"TensorFlow\" & \"Keras\", and \"scikit-learn\") for constructing them, and illustrate their use with a standard example.  The online text by Michael Nielsen, https://neuralnetworksanddeeplearning.com/index.html, provides a very clear discussion of neural networks in much more detail and greater breadth than this module.  It also provides Python code using simple functions for creating a neural network that identifies handwritten digits.  That code does not use the libraries mentioned above, which are designed to streamline the process of neural network construction, leading to code that is more compact and simpler.  \n",
    "\n",
    "There are two broad categories of approaches to AI: ***symbolic reasoning*** (\"top-down\"), based on the processing of symbols according to specified rules, and ***connectionist*** (\"bottom-up\") systems that mimic the structure of brains.  Neural networks are the prime example of a connectionist system.  (Other approaches to AI are described here: <a href=\"https://www.dummies.com/article/technology/information-technology/ai/general-ai/5-main-approaches-ai-learning-254207/\">Artificial Intelligence for Dummies</a>.)  An authoritative text on deep learning using the connectionist approach is available (freely) in electronic form at https://www.deeplearningbook.org/.\n",
    "\n",
    "(For a nice discussion of the two main approaches to AI, check out the podcast <a href=\"https://www.npr.org/podcasts/452538775/on-the-media\">\"It's a Machine's World\"</a> starting at the 16:30 mark.  That segment features one of the pioneers in the development of neural networks, Geoffrey Hinton. The \"vectors\" he refers to are the sets of \"weights\" discussed below.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Scientist Profile</font>\n",
    "\n",
    "**Alan Turing** was a British scientist who is most well known for cracking the Germans' \"Enigma machine,\" thereby significantly contributing to the Allies’ victory in World War II, and for proposing the \"Turing test\" for determining whether a computer's \"thinking\" is indistinguishable from that of a human.  He is now considered the father of modern computer science because of his work both during and after the war.  After the Allies' victory, Turing worked at the National Physical Laboratory in London on the first stored-program computer, and he used his work there for other projects.  Arguably the most interesting of his side projects was his work in morphogenesis and his discovery of Turing Patterns.  He discovered several recurring biological patterns in nature using math and his new computer to model them.  Unfortunately, this was one of his final projects before his death in 1954.  Two years earlier he was convicted of indecency, the charge that came with being gay in England at the time, and was put on corrective hormones as punishment.  This led to a downward spiral for Turing that ended in his suicide at the young age of 41.  Despite his short life, he made important contributions to many fields, including computer science, cryptology, physics, chemistry, and biology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './Images/Alan_Turing.jpg'  width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>(Image credit: National Physical Laboratory Archives, U.K., https://www.npl.co.uk/famous/alan-turing)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">16.1 Basics of Neural Networks</font>\n",
    "\n",
    "### <font color=\"blue\">16.1.1 What is a neural network?</font>\n",
    "\n",
    "An (***artificial***) ***neural network*** (**NN**, sometimes **ANN**) is a simplified model of a biological brain consisting of simulated ***neurons*** arranged in ***layers*** and tied together via ***connections***.  Neurons in NNs can be thought of as simple computing units that take an input and produce an output.  There are different models for NNs based on the way they learn.  The one discussed here is an example of a type called a (multi-layer) ***perceptron*** network.\n",
    "\n",
    "Figure 1 shows the simplest example of a multi-layer NN, involving an ***input layer***, an ***output layer***, and a ***hidden layer*** between them.  (Modern NNs often use more than one hidden layer.  Simple tasks -- e.g., modeling logic gates acting on binary inputs -- can be performed by networks with no hidden layers.)  The figure depicts a ***feedforward*** network, in which data flows left to right from the input layer to the hidden layer(s) to the output layer, but not in the opposite direction.  This is the type of network that will be presented in this module.\n",
    "\n",
    "Two other commonly used types of network are ***convolutional neural networks***, similar to feedforward networks and used primarily for computer vision applications, and ***recurrent neural networks***, which more closely mimic the operation of biological brains.  They allow backward-flowing data and are useful for analyzing time series information such as daily stock values.  There are many other types of neural network, but this module will focus on just feedforward networks.  (The Wikipedia page titled \"Types of artificial neural networks\" has more information.)\n",
    "\n",
    "The connections between the neurons in a network, shown by the arrows in Figure 1, can have different strengths, represented by the thickness of the arrows.  The strengths affect how strongly the output of a neuron affects the state of a neuron (to its right) to which it's connected.  Note that each neuron in a given layer (apart from the output layer) is connected to *every* neuron in the next layer to its right.  Also keep in mind that the layers often are *two-dimensional*, but such 2-D arrays always can be rearranged into 1-D columns, as depicted in the figure.  The connection weights are where information is stored in a NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './Images/Neural_network.png'  width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Figure 1: Simple neural network</center> \n",
    "\n",
    "<center>(Image credit: By User:Wiso - from en:Image:Neural network example.svg, vetorialization of en:Image:Neural network example.png, Public Domain, https://commons.wikimedia.org/w/index.php?curid=5084582 )</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A standard example of what such a NN can be used for is ***digit classification***: identifying what digit from 0 through 9 a given handwritten digit corresponds to.  In that case, the input layer would be a 2-D array of neurons, whose values would be the grayscale values (say, between 0, representing black, and 1, representing white) of the pixels in a 2-D image of the digit.  You can see examples of such images below in this notebook.  \n",
    "\n",
    "The output layer of the network would be a set of ten neurons: activation of the first one would represent an identification of the handwritten number as $0$, activation of the second one would represent $1$, and so on.  Ideally, only one output neuron would be activated -- i.e., have a value greater than zero -- for a given input, with all other output neurons having values of zero.  In actual networks many or all of the output neurons may have values other than zero, but the output of the \"desired\" neuron will be significantly greater than the outputs of the others.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you might want to watch this YouTube video <a href=\"https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\">3Blue1Brown: But what is a neural network? | Chapter 1</a> if it's available.  It will give a preview of the next section, with nice animations.  (Note that there's some content after the credits.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">16.1.2 Neuron Inputs and Outputs</font>\n",
    "\n",
    "Those grayscale values of the input neurons will provide input values for *each* of the neurons in the next layer, but not directly. As mentioned above, each input neuron's output is modified by a connection strength, or ***weight***, between that neuron and one in the next layer.  (These weights model the strength of the interactions between neurons in biological brains.)  \n",
    "\n",
    "Let's denote the weight for the connection between the $i^{\\textrm{th}}$ input neuron and the $j^{\\textrm{th}}$ neuron in the next layer by $w_{ji}$.  Then, labeling the output of the $i^{\\textrm{th}}$ neuron in the input layer by $x_i$, the total input to the $j^{\\textrm{th}}$ neuron (call the total input $y_j$) in the next layer is the ***weighted sum*** of the individual inputs from the neurons in the input layer:\n",
    "\n",
    "$$y_j = \\sum_i w_{ji} x_i .  \\hspace{10em}  [1]$$\n",
    "\n",
    "The input from the $i^{\\textrm{th}}$ neuron is *weighted* by its connection weight.  Clearly, a neuron in the input layer that has a stronger connection to a neuron in the next layer will have more influence over that neuron's \"activation.\"\n",
    "\n",
    "Note that the expression in [1] can be interpreted as a weight *matrix* multiplying a *column vector* of $x_i$ values, which produces a *column vector* of $y_j$ values.  (In general, the weight matrix will not be square, since the number of neurons in the two layers won't be equal.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Activation Functions</font>\n",
    "\n",
    "What, then, is the *output* of the $j^{\\textrm{th}}$ neuron?  It is determined by an ***activation function*** representing the internal behavior of the neuron.  Two activation functions that are commonly used for simple applications are:\n",
    "\n",
    "- The ***logistic*** function, often called the ***sigmoid*** function (which actually refers to a *group* of \"s\"-shaped functions), generally used in networks with few hidden layers: \n",
    "\n",
    "$$S(x) = \\frac{1}{1 + e^{-x}}.  \\hspace{9.5em}  [2]$$\n",
    "\n",
    "Execute the next two code cells to see a plot of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {display: table-cell; text-align: center; vertical-align: middle;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CODE FOR CENTERING PLOTS\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {display: table-cell; text-align: center; vertical-align: middle;}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'S(x)')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAEUCAYAAACrqHaDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1aklEQVR4nO3deVxU5f4H8M8szAzrsOkACoipiOEKaWCmpmJoLmU31JtLWcnNfqaYN7l5M80kbdHrNbXMJbsuZKYtYkm5YaAhahqSuQIKSCACsgwwc35/AJMjMLIMHJbP+/Wa1zDPPGfmO8eBj+ec5zxHIgiCACIiIqqWVOwCiIiImjMGJRERkQkMSiIiIhMYlERERCYwKImIiExgUBIREZnAoCQiIjKBQUlERGQCg5KIiMgEBiW1eidOnMCTTz4JDw8PKJVKaDQaBAQEYN68eUb9hgwZgiFDhohTZC1du3YNEokEW7ZsuW/ft956CxKJ5L79pk+fDolEUu3tu+++M0PV9bds2TLs3bu3Svvhw4chkUhw+PDhJq+J2h652AUQNaZ9+/Zh7NixGDJkCFasWAFXV1ekp6fj5MmT2LlzJz744AND37Vr14pYae24uroiLi4ODzzwgFlf19LSEgcPHqzS3r17d7O+T10tW7YMTz/9NMaPH2/U3q9fP8TFxaFHjx7iFEZtCoOSWrUVK1bAy8sLP/zwA+Tyv77uEydOxIoVK4z6toQ/ukqlEg8//LDZX1cqlTbK6zYWOzu7FlUvtWzc9UqtWnZ2NpydnY1CspJUavz1r27X6/Xr1/H000/D1tYW9vb2+Pvf/474+Pgquz+nT58OGxsb/P777xg5ciSsra3h6uqKd999FwBw/PhxPPLII7C2tka3bt3w2WefVannt99+w7hx4+Dg4ACVSoU+ffpU6VfTrtd9+/ahT58+UCqV8PLywvvvv1+HtWRaTbs5q6ulcj1cunQJo0aNgo2NDdzd3TFv3jxotVqj5bVaLZYsWQIfHx+oVCo4OTlh6NChiI2NBQBIJBIUFBTgs88+M+wKrvz3qammb775BgEBAbCysoKtrS1GjBiBuLg4oz6Vu6QTExMxadIkqNVqaDQaPP/888jNzTXLOqPWhUFJrVpAQABOnDiB2bNn48SJEygtLa31sgUFBRg6dCgOHTqE5cuX44svvoBGo0FISEi1/UtLS/HUU09h9OjR+PrrrxEcHIzw8HD861//wrRp0/D8889jz5498Pb2xvTp05GQkGBY9sKFCwgMDERiYiJWr16Nr776Cj169MD06dOrbPne66effsK4ceNga2uLnTt34r333sMXX3yBzZs31/qzAkBZWZnRTafT1Wn5u9fD2LFjMWzYMHz99dd4/vnnsXLlSixfvtzovYKDg/H222/jiSeewJ49e7BlyxYEBgYiJSUFABAXFwdLS0uMGjUKcXFxiIuLM7l7fPv27Rg3bhzs7OywY8cObNy4ETk5ORgyZAiOHTtWpf+ECRPQrVs37N69GwsWLMD27dsxd+7cen1mauUEolYsKytLeOSRRwQAAgDBwsJCCAwMFCIiIoT8/HyjvoMHDxYGDx5sePzRRx8JAIT9+/cb9Zs5c6YAQNi8ebOhbdq0aQIAYffu3Ya20tJSoV27dgIA4dSpU4b27OxsQSaTCWFhYYa2iRMnCkqlUkhJSTF6r+DgYMHKykq4ffu2IAiCcPXq1SrvPWDAAMHNzU0oKioytOXl5QmOjo5CbX7FK2u/9zZw4EBBEATh0KFDAgDh0KFDRstVV0vla33xxRdGfUeNGiV4e3sbHm/dulUAIGzYsMFkbdbW1sK0adOqtN9bk06nE9zc3ISePXsKOp3O0C8/P19o3769EBgYaGhbtGiRAEBYsWKF0Wu+/PLLgkqlEvR6vcmaqO3hFiW1ak5OToiJiUF8fDzeffddjBs3Dn/88QfCw8PRs2dPZGVl1bjskSNHYGtri8cff9yofdKkSdX2l0gkGDVqlOGxXC5Hly5d4Orqir59+xraHR0d0b59eyQnJxvaDh48iGHDhsHd3d3oNadPn47CwsIquw8rFRQUID4+Hk899RRUKpWh3dbWFmPGjKnxs93L0tIS8fHxRreNGzfWevm7SSSSKu/dq1cvo8+7f/9+qFQqPP/88/V6j3tduHABaWlpmDJlitEudRsbG0yYMAHHjx9HYWGh0TJjx46tUmNxcTEyMzPNUhO1HhzMQ22Cv78//P39AZTvGnz99dexcuVKrFixosZdm9nZ2dBoNFXaq2sDACsrK6OwAgCFQgFHR8cqfRUKBYqLi43ey9XVtUo/Nzc3w/PVycnJgV6vh4uLS5XnqmuriVQqNayfhqpuPSiVSqPP++eff8LNza3KceL6qlw/Na1DvV6PnJwcWFlZGdqdnJyq1AgARUVFZqmJWg9uUVKbY2FhgUWLFgEoH0BTEycnJ9y8ebNKe0ZGhtlrcnJyQnp6epX2tLQ0AICzs3O1yzk4OEAikVRbk7nqrAy9ewfjmNoav5927dohLS0Ner2+QbVVqgy9mtahVCqFg4ODWd6L2h4GJbVq1f3hBICkpCQAf22xVWfw4MHIz8/H/v37jdp37txpvgIrDBs2DAcPHjQEY6WtW7fCysqqxlMhrK2t0b9/f3z11VdGW2z5+fn49ttvzVJbp06dAABnz541av/mm2/q/ZrBwcEoLi6+78QJSqWyVlt43t7e6NChA7Zv3w5BEAztBQUF2L17t2EkLFF9cNcrtWojR45Ex44dMWbMGHTv3h16vR5nzpzBBx98ABsbG7z66qs1Ljtt2jSsXLkSzz77LJYuXYouXbpg//79+OGHHwBUPb2kIRYtWoTvvvsOQ4cOxZtvvglHR0ds27YN+/btw4oVK6BWq2tc9u2338bjjz+OESNGYN68edDpdFi+fDmsra1x69atBtfm4uKC4cOHIyIiAg4ODvD09MRPP/2Er776qt6vOWnSJGzevBmhoaG4cOEChg4dCr1ejxMnTsDHxwcTJ04EAPTs2ROHDx/Gt99+C1dXV9ja2sLb27vK60mlUqxYsQJ///vf8cQTT2DmzJnQarV47733cPv2bcNpOkT1wS1KatUWLlwIBwcHrFy5EmPHjkVwcDBWr16N4cOH45dffkHPnj1rXNba2hoHDx7EkCFD8M9//hMTJkxASkqK4RQFe3t7s9Xp7e2N2NhYeHt7Y9asWRg/fjx+++03bN68GfPnzze57IgRI7B3717k5eUhJCQEYWFhmDBhgtkGygDA559/jmHDhuH111/H3/72N9y4cQM7duyo9+vJ5XJERUUhPDwce/bswbhx4zB16lQcO3YMnp6ehn7/+c9/0LVrV0ycOBEPPfQQZs6cWeNrTp48GXv37kV2djZCQkLw3HPPwc7ODocOHcIjjzxS71qJJMLd+ymI6L6WLVuGhQsXIiUlBR07dhS7HCJqZNz1SmTCmjVrAJTPeVpaWoqDBw9i9erVePbZZxmSRG0Eg5LIBCsrK6xcuRLXrl2DVquFh4cHXn/9dSxcuFDs0oioiXDXKxERkQkczENERGQCg5KIiMgEBiUREZEJbW4wj16vR1paGmxtbSGRSMQuh4iIRCIIAvLz8+8773CbC8q0tLQqV2ggIqK2KzU11eTpXm0uKG1tbQGUrxg7OzuRqyEiIrHk5eXB3d3dkAs1aXNBWbm71c7OjkFJRET3PQzHwTxEREQmMCiJiIhMEDUojx49ijFjxsDNzQ0SiQR79+697zJHjhyBn58fVCoVOnfujPXr1zd+oURE1GaJGpQFBQXo3bu3YeLp+7l69SpGjRqFQYMG4fTp0/jXv/6F2bNnY/fu3Y1cKRERtVWiDuYJDg5GcHBwrfuvX78eHh4eWLVqFQDAx8cHJ0+exPvvv48JEyY0UpVERK2TIAgQBECo/BlA5ezfAgTcPRN4eT/B6LHh53tes/r2ux/cp677dahgpZBDIW/87b0WNeo1Li4OQUFBRm0jR47Exo0bUVpaCgsLiyrLaLVaaLVaw+O8vLxGr5OI2ha9XkBBSRkKtDrc0ZbijlaHO8VluKMtRYFWh+IyHbSlemjL9Cgu1UFbpoe2TIfi0vL7kjI9ynQCyvR6lN51X6qrbBeg0+uh0wvQC4BOL1T8/Ne9XkD5vb484CrbBFTcC3/d3x2ILdlHk/thdC/XRn+fFhWUGRkZ0Gg0Rm0ajQZlZWXIysqCq2vVFRYREYHFixc3VYlE1ErkFpbixu0iZN3RIrtAi6z8EmRV3GcXaMvb75Qgr6gUBSU6sculRtSighKoer5L5WZ+TefBhIeHIywszPC48gRTIqLbhSW4ll2Ia1kFuJZdUHFfiGvZBbhdWFrn15NJJbBRymGjlMNWVX5vpZRDJZdCZSGDUi6F0kIKpVwGVcW9Ui6FQi6FXCaFhVRSfi+TQC6VQi6TwEImgUwqhVwqgVQigUwqgUwKyKRSyCQSSKXl7yuVVN5g+FkiASQVjw33ACABJCjvK6lok1S0oWKZim6Gv61GfSrUdPrhve13L1Nzn3ufv/8Uo9ImmoW0RQWli4sLMjIyjNoyMzMhl8vh5ORU7TJKpRJKpbIpyiOiZqyoRIdfr99GQnIOTl67hV+v5+JWQYnJZZysFWhnq4STjQLONko4WZf/3M6m/N7JRgm1pYUhGJVyKeeQboVaVFAGBATg22+/NWo7cOAA/P39qz0+SURt15/5WiQk30L8tRycTM5B4o1clOmrHpjT2Cnh6WQNLydreDpbld87WaOTsxWsFC3qTyQ1ElG/BXfu3MGlS5cMj69evYozZ87A0dERHh4eCA8Px40bN7B161YAQGhoKNasWYOwsDC8+OKLiIuLw8aNG7Fjxw6xPgIRNSMZucXYe+YG9py6gQs386s8395WCf9ODvDzdISfpwO6aWwYhnRfon5DTp48iaFDhxoeVx5LnDZtGrZs2YL09HSkpKQYnvfy8kJUVBTmzp2Ljz76CG5ubli9ejVPDSFqwwpLynAg8SZ2n7qOY5eyDKM5JRLAW2MLP08H+HdygL+nIzo6WHLXKNWZRBBawyDh2svLy4NarUZubi4nRSdqofR6ASeu3sJXp64j6ly60ajThzo5YEK/jnjc1wX2VgoRq6TmrrZ5wH0ORNRilOn02BGfivWHL+PG7SJDu4ejFZ7q1wFP9u0ATydrESuk1ohBSUQtQuzlLCz59jx+zyg/9mirlGN0L1dM8OsIf08H7lKlRsOgJKJmLfVWId7Zl4TvE8tPDVNbWiBsRDeEPOQOlYVM5OqoLWBQElGzVKAtw7rDl/FJzBWUlOkhk0rw7AAPzBneDQ7WPPZITYdBSUTNil4v4Otfb+Dd/b/jZl75PM2BDzhh0ZgH4e1iK3J11BYxKImo2cjILcas7aeQkJwDAHB3tMTC0T0Q1EPDY5AkGgYlETULFzLyMX3zL0jPLYaVQoZZQ7tgxiNePA5JomNQEpHo4i5n46XPTyK/uAyd21ljy/T+8HCyErssIgAMSiIS2ddnbmD+rrMo0enh7+mADVP9OViHmhUGJRGJQhAEfHL0CiL2/w4ACPZ1wcqQPtzVSs0Og5KImpxOL2DJt4n4LC4ZAPDcwE5YOLoHZE11gUGiOmBQElGTKi7VYfaO0zhw/iYAYOFoH7wwqLPIVRHVjEFJRE3mVkEJXvgsHqdSbkMhk+LDkN54opeb2GURmcSgJKImUVyqw5SNJ5CYlgc7lRwbpvpjQGcnscsiui8GJRE1OkEQ8O+9vyExLQ+O1gpEvvQwumo4yw61DFKxCyCi1m9nfCp2JVyHVAKsmdSXIUktCoOSiBrV2eu3sejrRADAayO9EdjFWeSKiOqGQUlEjSanoAT/+N8plOj0GO6jQeijD4hdElGdMSiJqFHo9AJejTyDG7eL4OlkhQ+e6Q0pz5OkFohBSUSN4j8/XcTRP/6EykKK9c/6QW1pIXZJRPXCoCQiszv0eyZW/3QRALDsyZ7wcbUTuSKi+mNQEpFZpd4qxJzIMwCAZx/2wFP9OopbEFEDMSiJyGyKS3X4x7YE5BaVore7Pf79RA+xSyJqMAYlEZnNoq8T8duN8kkF1v29H5RyXgmEWj7Rg3Lt2rXw8vKCSqWCn58fYmJiTPbftm0bevfuDSsrK7i6uuK5555DdnZ2E1VLRDX57mwaIk+mQiIBVk/sCzd7S7FLIjILUYMyMjISc+bMwRtvvIHTp09j0KBBCA4ORkpKSrX9jx07hqlTp2LGjBlITEzErl27EB8fjxdeeKGJKyeiuxWX6rBsXxIA4P+GdsEjXTmpALUeogblhx9+iBkzZuCFF16Aj48PVq1aBXd3d6xbt67a/sePH0enTp0we/ZseHl54ZFHHsHMmTNx8uTJJq6ciO72acwVpOUWw02twstDu4hdDpFZiRaUJSUlSEhIQFBQkFF7UFAQYmNjq10mMDAQ169fR1RUFARBwM2bN/Hll19i9OjRNb6PVqtFXl6e0Y2IzCczrxhrD18GALwe3B0qCx6XpNZFtKDMysqCTqeDRqMxatdoNMjIyKh2mcDAQGzbtg0hISFQKBRwcXGBvb09/vvf/9b4PhEREVCr1Yabu7u7WT8HUVv3/oELKCzRoa+HPcb25rUlqfURfTCPRGI8pZUgCFXaKp0/fx6zZ8/Gm2++iYSEBHz//fe4evUqQkNDa3z98PBw5ObmGm6pqalmrZ+oLfvtRi52JVwHAPz7iR41/u4StWSiXY/S2dkZMpmsytZjZmZmla3MShERERg4cCDmz58PAOjVqxesra0xaNAgLF26FK6urlWWUSqVUCqV5v8ARG2cIAh4+7vzEARgbG839PNwELskokYh2halQqGAn58foqOjjdqjo6MRGBhY7TKFhYWQSo1LlsnKj4cIgtA4hRJRtX5IvIkTV29BKZfi9eDuYpdD1GhE3fUaFhaGTz/9FJs2bUJSUhLmzp2LlJQUw67U8PBwTJ061dB/zJgx+Oqrr7Bu3TpcuXIFP//8M2bPno3+/fvDzY3HRoiairZMh4j95aeDvPRoZ3TgOZPUiom26xUAQkJCkJ2djSVLliA9PR2+vr6IioqCp6cnACA9Pd3onMrp06cjPz8fa9aswbx582Bvb4/HHnsMy5cvF+sjELVJW2OTkZxdiPa2SoQO5jUmqXWTCG1sn2VeXh7UajVyc3NhZ8crGhDVVfYdLYa8fxj5xWVY8XQvPOPPkeTUMtU2D0Qf9UpELcvKH/9AfnEZHnSzw9O8Mgi1AQxKIqq1P27mY/uJ8sMhbz7RA1IpTweh1o9BSUS1tnRfEvQC8PiDLhjQ2UnscoiaBIOSiGrl0IVMHP3jTyhkUoSP4ukg1HYwKInovnR6Ae9UXB3kuYGd4OlkLXJFRE2HQUlE9xV9/iYuZd6B2tICsx7j1UGobWFQEtF9bYi5AgB49mEP2KksRK6GqGkxKInIpITkHCQk50Ahk2JaQCexyyFqcgxKIjLp04qtyfF93dDeTiVyNURNj0FJRDVKzi7A94nlV/h5YVBnkashEgeDkohqtPHYVQgCMMS7HbppbMUuh0gUDEoiqlZOQQl2nSy/KPNL3JqkNoxBSUTV2nYiGUWlOjzoZoeABzgLD7VdDEoiqqK4VIctsckAgBcHdYZEwjldqe1iUBJRFd+cSUPWHS1c1SqM7uUqdjlEomJQEpERvV7AJxWnhDw/0AsWMv6ZoLaNvwFEZOTIH3/iUuYd2CjlCOnPizITMSiJyEjldHWT+rtzujoiMCiJ6C6/3chF7OVsyKUSPDfQS+xyiJoFBiURGVRuTT7RyxVu9pYiV0PUPDAoiQgAkHa7CN+dTQfA6eqI7sagJCIAwOafr0KnFxD4gBN8O6jFLoeo2WBQEhHyikux45dUAMCLj3JrkuhuDEoiwhfxqbijLUPX9jYY0q2d2OUQNSuiB+XatWvh5eUFlUoFPz8/xMTEmOyv1WrxxhtvwNPTE0qlEg888AA2bdrURNUStT56vYD/HS+frm7GI16cro7oHnIx3zwyMhJz5szB2rVrMXDgQHz88ccIDg7G+fPn4eHhUe0yzzzzDG7evImNGzeiS5cuyMzMRFlZWRNXTtR6HL+SjWvZhbBVyjG2j5vY5RA1OxJBEASx3nzAgAHo168f1q1bZ2jz8fHB+PHjERERUaX/999/j4kTJ+LKlStwdHSs13vm5eVBrVYjNzcXdnZ29a6dqLWYtf0U9p1Nx5SHPfH2eF+xyyFqMrXNA9F2vZaUlCAhIQFBQUFG7UFBQYiNja12mW+++Qb+/v5YsWIFOnTogG7duuG1115DUVFRje+j1WqRl5dndCOicll3tDiQmAEAmNS/+r04RG2daLtes7KyoNPpoNFojNo1Gg0yMjKqXebKlSs4duwYVCoV9uzZg6ysLLz88su4detWjccpIyIisHjxYrPXT9QafJlwHaU6AX3c7dHDjXtYiKoj+mCeewcOCIJQ42ACvV4PiUSCbdu2oX///hg1ahQ+/PBDbNmypcatyvDwcOTm5hpuqampZv8MRC2RXi9gxy8pAIDJ3JokqpFoW5TOzs6QyWRVth4zMzOrbGVWcnV1RYcOHaBW/3UytI+PDwRBwPXr19G1a9cqyyiVSiiVSvMWT9QKxF7ORnLFIJ4nevOak0Q1EW2LUqFQwM/PD9HR0Ubt0dHRCAwMrHaZgQMHIi0tDXfu3DG0/fHHH5BKpejYsWOj1kvU2lRuTT7ZrwOsFKIOgCdq1kTd9RoWFoZPP/0UmzZtQlJSEubOnYuUlBSEhoYCKN9tOnXqVEP/yZMnw8nJCc899xzOnz+Po0ePYv78+Xj++edhackJnIlq6898LX7gIB6iWhH1v5EhISHIzs7GkiVLkJ6eDl9fX0RFRcHT0xMAkJ6ejpSUFEN/GxsbREdH4//+7//g7+8PJycnPPPMM1i6dKlYH4GoRdqVkIoyvYC+HvbwceUgHiJTRD2PUgw8j5LaOr1ewJD3DyPlViFWPN0Lz/i7i10SkShqmwd13qIUBAFHjhxBTEwMrl27hsLCQrRr1w59+/bF8OHD4e7OXzqi5uzny1lIuVUIW5UcY3pxJh6i+6n1McqioiIsW7YM7u7uCA4Oxr59+3D79m3IZDJcunQJixYtgpeXF0aNGoXjx483Zs1E1ADbT5QfzniqbwdYKmQiV0PU/NV6i7Jbt24YMGAA1q9fj5EjR8LCwqJKn+TkZGzfvh0hISFYuHAhXnzxRbMWS0QNk5lfjOjzNwEAkwZwEA9RbdQ6KPfv3w9fX9PzQHp6eiI8PBzz5s1DcnJyg4sjIvPadfI6yvQC+nnYo7sLj9ET1Uatd73eLyTvplAoqj35n4jEo9cL2BlfvtuVp4QQ1V69zqP897//DZ1OV6U9NzcXkyZNanBRRGR+xy5lIfVWEWxVcjzBQTxEtVavoNy6dSsGDhyIy5cvG9oOHz6Mnj174tq1a+aqjYjMqHIQz4R+HTmIh6gO6hWUZ8+eRadOndCnTx9s2LAB8+fPR1BQEKZPn45jx46Zu0YiaqDMvGL8mFQxiIe7XYnqpF4z86jVauzcuRNvvPEGZs6cCblcjv3792PYsGHmro+IzGBXQvkgHj9PB3i72IpdDlGLUu+5Xv/73/9i5cqVmDRpEjp37ozZs2fj119/NWdtRGQGd19Oi1uTRHVXr6AMDg7G4sWLsXXrVmzbtg2nT5/Go48+iocffhgrVqwwd41E1AAxl7JwPacIdio5nujFy2kR1VW9grKsrAxnz57F008/DQCwtLTEunXr8OWXX2LlypVmLZCIGmb7ifJzmp/q1xEqCw7iIaqreh2jvPcakpVGjx6Nc+fONaggIjKfm3nF+DEpEwAwmTPxENWL2a9H6ezsDKB88nQiEteuk6nQ6QX4ezqgm4aDeIjqo9ZB6ePjg+3bt6OkpMRkv4sXL+If//gHli9f3uDiiKj+dHoBO35JBcCtSaKGqPWu148++givv/46Zs2ahaCgIPj7+8PNzQ0qlQo5OTk4f/48jh07hvPnz+OVV17Byy+/3Jh1E9F9HL34J27cLoLa0gKjenIQD1F91TooH3vsMcTHxyM2NhaRkZHYvn07rl27hqKiIjg7O6Nv376YOnUqnn32Wdjb2zdiyURUGzsqL6fVrwMH8RA1QJ0H8wQGBiIwMLAxaiEiM7mZV4yffq8YxMNzJ4kapE6DeU6cOIH9+/cbtW3duhVeXl5o3749XnrpJWi1WrMWSER1FxlfPojnoU4O6MpBPEQNUqegfOutt3D27FnD43PnzmHGjBkYPnw4FixYgG+//RYRERFmL5KIak+nFxAZz0E8ROZSp6A8c+aM0XyuO3fuxIABA7BhwwaEhYVh9erV+OKLL8xeJBHV3tE//hrEE+zLQTxEDVWnoMzJyYFGozE8PnLkCB5//HHD44ceegipqanmq46I6mzbXZfT4iAeooarU1BqNBpcvXoVAFBSUoJTp04hICDA8Hx+fj4sLCzMWyER1VpGbjEO/l5+Oa3JA9xFroaodahTUD7++ONYsGABYmJiEB4eDisrKwwaNMjw/NmzZ/HAAw+YvUgiqp3I+FToBaB/J0d0ac9BPETmUKegXLp0KWQyGQYPHowNGzZgw4YNUCgUhuc3bdqEoKCgOhWwdu1aeHl5QaVSwc/PDzExMbVa7ueff4ZcLkefPn3q9H5ErVX5IJ7y3a4cxENkPnU6j7Jdu3aIiYlBbm4ubGxsIJMZH//YtWsXbGxsav16kZGRmDNnDtauXYuBAwfi448/RnBwMM6fPw8Pj5p/0XNzczF16lQMGzYMN2/erMtHIGq1jvyRibTcYthbWeBxXxexyyFqNeo1Kbpara4SkgDg6OhotIV5Px9++CFmzJiBF154AT4+Pli1ahXc3d2xbt06k8vNnDkTkydPNjo+StTWbecgHqJGYfarh9RWSUkJEhISquyqDQoKQmxsbI3Lbd68GZcvX8aiRYtq9T5arRZ5eXlGN6LWJu12EQ5WzMQziTPxEJmVaEGZlZUFnU5ndLoJUD6yNiMjo9plLl68iAULFmDbtm2Qy2u31zgiIgJqtdpwc3fnSEBqfb44WT6IZ4CXI7q0r/3hDyK6P9GCspJEIjF6LAhClTYA0Ol0mDx5MhYvXoxu3brV+vXDw8ORm5truPE8T2ptynR6zsRD1IjqPCm6uTg7O0Mmk1XZeszMzKyylQmUn6N58uRJnD59Gq+88goAQK/XQxAEyOVyHDhwAI899liV5ZRKJZRKZeN8CKJm4PCFP5GeWwwHDuIhahSibVEqFAr4+fkhOjraqD06Orraq5PY2dnh3LlzOHPmjOEWGhoKb29vnDlzBgMGDGiq0omalW0nkgEAT/t1hFLOQTxE5ibaFiUAhIWFYcqUKfD390dAQAA++eQTpKSkIDQ0FED5btMbN25g69atkEql8PX1NVq+ffv2UKlUVdqJ2opLmfk4dOFPSCTA5AGeYpdD1CqJGpQhISHIzs7GkiVLkJ6eDl9fX0RFRcHTs/wXPj09HSkpKWKWSNSsfRpTPqXkCB8NvJytRa6GqHWSCIIgiF1EU8rLy4NarUZubi7s7OzELoeo3v7M12Lg8oMoKdPjy9AA+HdyFLskohaltnkg+qhXIqqfz+OuoaRMjz7u9vDzdBC7HKJWi0FJ1AIVlejw+fHyQTwvPdq52lOqiMg8GJRELdCXp64jp7AU7o6WGPkgTwkhakwMSqIWRqcXsDHmCgBgxkAvyKTcmiRqTAxKohYm+vxNXMsuhNrSAn/z55SMRI2NQUnUwmyo2Jp89mEPWCtFPcOLqE1gUBK1IAnJOUhIzoFCJsW0gE5il0PUJjAoiVqQTyu2Jsf1cUN7O5XI1RC1DQxKohYiObsA3yeWX0TgxUc7i1wNUdvBoCRqITYeuwpBAIZ4t0M3ja3Y5RC1GQxKohYgp6AEu05eBwC8NIhbk0RNiUFJ1AJsO5GMolIderjaIeABJ7HLIWpTGJREzVxxqQ5bYjldHZFYGJREzdw3Z9KQdUcLV7UKo3u5il0OUZvDoCRqxvR6AZ9UnBLy3MBOsJDxV5aoqfG3jqgZ+zHpJi5l3oGNUo6J/T3ELoeoTWJQEjVTpTo93v3+dwDAlABP2KksRK6IqG1iUBI1U/87nowrfxbAyVqBl4c8IHY5RG0Wg5KoGbpdWIJVP14EAIQFdYMttyaJRMOgJGqGVv14EblFpejuYosQXkqLSFQMSqJm5lLmHfzvePl5kwtH94CcI12JRMXfQKJmZllUEsr0AoZ1b49HujqLXQ5Rm8egJGpGYi7+iYO/Z0IuleBfo33ELoeIwKAkajbKdHos/S4JQPnpIA+0sxG5IiICmkFQrl27Fl5eXlCpVPDz80NMTEyNfb/66iuMGDEC7dq1g52dHQICAvDDDz80YbVEjSfyZCou3MyH2tICrw7rKnY5RFRB1KCMjIzEnDlz8MYbb+D06dMYNGgQgoODkZKSUm3/o0ePYsSIEYiKikJCQgKGDh2KMWPG4PTp001cOZF55RWX4sMDfwAA5gzvCnsrhcgVEVEliSAIglhvPmDAAPTr1w/r1q0ztPn4+GD8+PGIiIio1Ws8+OCDCAkJwZtvvlmr/nl5eVCr1cjNzYWdnV296iYyt4ioJHx89Ao6t7PGD3Me5ZyuRE2gtnkg2m9jSUkJEhISEBQUZNQeFBSE2NjYWr2GXq9Hfn4+HB0da+yj1WqRl5dndCNqTlKyC7H552sAgIWjfRiSRM2MaL+RWVlZ0Ol00Gg0Ru0ajQYZGRm1eo0PPvgABQUFeOaZZ2rsExERAbVabbi5u/PkbWpeIvYnoUSnx6Cuzhjq3V7scojoHqL/1/Xei9AKglCrC9Pu2LEDb731FiIjI9G+fc1/XMLDw5Gbm2u4paamNrhmInM5fiUb+3/LgFRSPrkAL8pM1PzIxXpjZ2dnyGSyKluPmZmZVbYy7xUZGYkZM2Zg165dGD58uMm+SqUSSqWywfUSmZu2TIfF354HAEzs7wFvF1uRKyKi6oi2RalQKODn54fo6Gij9ujoaAQGBta43I4dOzB9+nRs374do0ePbuwyiRrNkm/PIyk9D/ZWFggb0U3scoioBqJtUQJAWFgYpkyZAn9/fwQEBOCTTz5BSkoKQkNDAZTvNr1x4wa2bt0KoDwkp06div/85z94+OGHDVujlpaWUKvVon0OorranXAd206kQCIBVoX0gbMN93oQNVeiBmVISAiys7OxZMkSpKenw9fXF1FRUfD09AQApKenG51T+fHHH6OsrAyzZs3CrFmzDO3Tpk3Dli1bmrp8ono5n5aHf+05BwB4dVhXDOEAHqJmTdTzKMXA8yhJTLlFpRi75hiSswsxuFs7bJ7+EKRSDuAhEkOzP4+SqK3R6wXM++JXJGcXooO9JVaF9GFIErUADEqiJrLuyGX8mHQTCpkU65/1g4M1p6kjagkYlERN4OdLWfjgwAUAwOJxD6JnRw4+I2opGJREjSw9twizd5yGXgD+5tcREx/i7FBELQmDkqgRlZTp8fK2U8guKEEPVzu8Pd6Xs+8QtTAMSqJGtHTfeZxOuQ07lRzrn/WDykImdklEVEcMSqJGsjXuGrbGJQMAVob0gYeTlcgVEVF9iDrhAFFrJAgC3j9wAR8dugwAmP1YFwzzMT1/MRE1XwxKIjMqKdNjwe6z+Or0DQDAnOFd8eqwriJXRUQNwaAkMpO84lL8438J+PlSNmRSCSKe7IlnOMKVqMVjUBKZQUZuMaZv/gW/Z+TDSiHD2r/34xyuRK0Eg5KogS5k5GP65l+QnlsMZxsltjz3EHw7cEIBotaCQUnUAHGXs/HS5yeRX1yGzu2s8dlz/eHuyNGtRK0Jg5Konr4+cwPzd51FiU4Pf08HfDrNH/ZWnL+VqLVhUBLV0bWsAizdl4Qfk24CAIJ9XbAypA8nEyBqpRiURLWUX1yKNYcuYdOxqyjVCZBLJZg5uDPmjfDm5bKIWjEGJdF96PUCvjx1HSu+v4CsO1oAwOBu7fDvJ3qgS3sbkasjosbGoCQyISE5B4u/TcTZ67kAAC9na/z7CR8M9W7Pyc2J2ggGJVE1rmUVYNWPf2DvmTQAgI1SjtnDumB6oBcUck6RTNSWMCiJKuQWlWLf2XTsPnUdCck5AACJpPwakvNHdkc7W6XIFRKRGBiU1KaV6fSIuZiFL09dR/T5mygp0wMApBLg0W7tEDaiG3p1tBe3SCISFYOS2hy9XsD59DzsOX0DX59JMwzQAQBvjS0m+HXAuD4doLFTiVglETUXDEpq9YpKdDiTehsJybdwMjkHp5JzkFdcZnjeyVqBsX3cMKFfRzzoZsdBOkRkhEFJrUqZTo+028X4LS0XJ6/lICH5FhLT8lCmF4z6WSlkGNytHSb064jB3u1gIeMAHSKqnuhBuXbtWrz33ntIT0/Hgw8+iFWrVmHQoEE19j9y5AjCwsKQmJgINzc3/POf/0RoaGgTVkxiK9PpceN2Ea5lF+JaVgGuZRfgWlYBkrMLkZpTiFKdUGUZFzsV/Ds5wN/TAf6dHNHdxRZyhiMR1YKoQRkZGYk5c+Zg7dq1GDhwID7++GMEBwfj/Pnz8PDwqNL/6tWrGDVqFF588UX873//w88//4yXX34Z7dq1w4QJE0T4BNRQer2AgpIyFGh1uKMtRX5xGW4XliLrjhZZd0qQfUeL7IKSKo91+qphWEkpl+KBdjbw83SAfycH+Hk6oIO9JXepElG9SARBqPkvTiMbMGAA+vXrh3Xr1hnafHx8MH78eERERFTp//rrr+Obb75BUlKSoS00NBS//vor4uLiavWeeXl5UKvVyM3NhZ2dXb3qFgQBtwtL79+vmuVq6lP5lADB6Im7n698rvznv17PsKwA6AXB8JxgeE6AXvjreb0g3PVzxTKCAJ0e0OnLn9fpBegEAXq9YGgr0wso0wko1ekrftajVCegTF9xrxNQotOhuFQPbZkO2lI9isv00Jbq/rov1eGOtgx3tJXh+NexwrpQyqXwdLJCJydrdHK2Lr93skInZ2u42Kk4pRwR3Vdt80C0LcqSkhIkJCRgwYIFRu1BQUGIjY2tdpm4uDgEBQUZtY0cORIbN25EaWkpLCwsqiyj1Wqh1f41qjEvL6/htev06Pt2dINfh/4il0pgo5LDWiGHvZUFnG2UcLJRwNlGCWcbBZys736sRHtbJcOQiJqEaEGZlZUFnU4HjUZj1K7RaJCRkVHtMhkZGdX2LysrQ1ZWFlxdXassExERgcWLF5uv8EZUuWdQYngsuedx5fMSQ+Pdz0klEkgqlpNUPFn5WFr5/F0/SyUVfSsey6TlbeX3EshlEsgkEkil5fcyqQQWMinkMgnkUiksZBLIZVJYSMv7ymVSKGRSqCxkUMqlUFpIoZLLqtzbqOSwUVbcKn5WyqXcNUpEzZLog3nu/eMoCILJP5jV9a+uvVJ4eDjCwsIMj/Py8uDu7l7fcgEACpkUl5eNqlpbNX3vLYthQETUsogWlM7OzpDJZFW2HjMzM6tsNVZycXGptr9cLoeTk1O1yyiVSiiV5p16TCKRQMa8IyJqE0QbH69QKODn54foaONjfdHR0QgMDKx2mYCAgCr9Dxw4AH9//2qPTxIRETWUqCeShYWF4dNPP8WmTZuQlJSEuXPnIiUlxXBeZHh4OKZOnWroHxoaiuTkZISFhSEpKQmbNm3Cxo0b8dprr4n1EYiIqJUT9RhlSEgIsrOzsWTJEqSnp8PX1xdRUVHw9PQEAKSnpyMlJcXQ38vLC1FRUZg7dy4++ugjuLm5YfXq1TyHkoiIGo2o51GKwRznURIRUctX2zzgHF5EREQmiH56SFOr3IA2x8QDRETUclXmwP12rLa5oMzPzweABp9LSURErUN+fj7UanWNz7e5Y5R6vR5paWmwtbVt0Mn/lRMXpKam8linGXG9Ng6u18bB9do4mmq9CoKA/Px8uLm5QSqt+Uhkm9uilEql6Nixo9lez87Ojr8gjYDrtXFwvTYOrtfG0RTr1dSWZCUO5iEiIjKBQUlERGQCg7KelEolFi1aZPZ5ZNs6rtfGwfXaOLheG0dzW69tbjAPERFRXXCLkoiIyAQGJRERkQkMSiIiIhMYlERERCYwKOvhnXfeQWBgIKysrGBvb19tn5SUFIwZMwbW1tZwdnbG7NmzUVJS0rSFtnCdOnWCRCIxui1YsEDsslqctWvXwsvLCyqVCn5+foiJiRG7pBbtrbfeqvK9dHFxEbusFufo0aMYM2YM3NzcIJFIsHfvXqPnBUHAW2+9BTc3N1haWmLIkCFITEwUpVYGZT2UlJTgb3/7G/7xj39U+7xOp8Po0aNRUFCAY8eOYefOndi9ezfmzZvXxJW2fJXXKq28LVy4UOySWpTIyEjMmTMHb7zxBk6fPo1BgwYhODjY6DqvVHcPPvig0ffy3LlzYpfU4hQUFKB3795Ys2ZNtc+vWLECH374IdasWYP4+Hi4uLhgxIgRhvm6m5RA9bZ582ZBrVZXaY+KihKkUqlw48YNQ9uOHTsEpVIp5ObmNmGFLZunp6ewcuVKscto0fr37y+EhoYatXXv3l1YsGCBSBW1fIsWLRJ69+4tdhmtCgBhz549hsd6vV5wcXER3n33XUNbcXGxoFarhfXr1zd5fdyibARxcXHw9fWFm5uboW3kyJHQarVISEgQsbKWZ/ny5XByckKfPn3wzjvvcPd1HZSUlCAhIQFBQUFG7UFBQYiNjRWpqtbh4sWLcHNzg5eXFyZOnIgrV66IXVKrcvXqVWRkZBh9d5VKJQYPHizKd7fNTYreFDIyMqDRaIzaHBwcoFAokJGRIVJVLc+rr76Kfv36wcHBAb/88gvCw8Nx9epVfPrpp2KX1iJkZWVBp9NV+S5qNBp+DxtgwIAB2Lp1K7p164abN29i6dKlCAwMRGJiIpycnMQur1Wo/H5W991NTk5u8nq4RVmhugP0995OnjxZ69er7hJegiA06NJerUFd1vPcuXMxePBg9OrVCy+88ALWr1+PjRs3Ijs7W+RP0bLc+53j97BhgoODMWHCBPTs2RPDhw/Hvn37AACfffaZyJW1Ps3lu8stygqvvPIKJk6caLJPp06davVaLi4uOHHihFFbTk4OSktLq/wPqa1pyHp++OGHAQCXLl3i/9xrwdnZGTKZrMrWY2ZmZpv/HpqTtbU1evbsiYsXL4pdSqtROYo4IyMDrq6uhnaxvrsMygrOzs5wdnY2y2sFBATgnXfeQXp6uuEf+cCBA1AqlfDz8zPLe7RUDVnPp0+fBgCjXxyqmUKhgJ+fH6Kjo/Hkk08a2qOjozFu3DgRK2tdtFotkpKSMGjQILFLaTW8vLzg4uKC6Oho9O3bF0D5MfcjR45g+fLlTV4Pg7IeUlJScOvWLaSkpECn0+HMmTMAgC5dusDGxgZBQUHo0aMHpkyZgvfeew+3bt3Ca6+9hhdffJEXd62luLg4HD9+HEOHDoVarUZ8fDzmzp2LsWPHwsPDQ+zyWoywsDBMmTIF/v7+CAgIwCeffIKUlBSEhoaKXVqL9dprr2HMmDHw8PBAZmYmli5diry8PEybNk3s0lqUO3fu4NKlS4bHV69exZkzZ+Do6AgPDw/MmTMHy5YtQ9euXdG1a1csW7YMVlZWmDx5ctMX2+TjbFuBadOmCQCq3A4dOmTok5ycLIwePVqwtLQUHB0dhVdeeUUoLi4Wr+gWJiEhQRgwYICgVqsFlUoleHt7C4sWLRIKCgrELq3F+eijjwRPT09BoVAI/fr1E44cOSJ2SS1aSEiI4OrqKlhYWAhubm7CU089JSQmJopdVotz6NChav+OTps2TRCE8lNEFi1aJLi4uAhKpVJ49NFHhXPnzolSKy+zRUREZAJHvRIREZnAoCQiIjKBQUlERGQCg5KIiMgEBiUREZEJDEoiIiITGJREREQmMCiJiIhMYFASERGZwKAkIiIygUFJ1Eb8+eefcHFxwbJlywxtJ06cgEKhwIEDB0SsjKh541yvRG1IVFQUxo8fj9jYWHTv3h19+/bF6NGjsWrVKrFLI2q2GJREbcysWbPw448/4qGHHsKvv/6K+Ph4qFQqscsiarYYlERtTFFREXx9fZGamoqTJ0+iV69eYpdE1KzxGCVRG3PlyhWkpaVBr9cjOTlZ7HKImj1uURK1ISUlJejfvz/69OmD7t2748MPP8S5c+eg0WjELo2o2WJQErUh8+fPx5dffolff/0VNjY2GDp0KGxtbfHdd9+JXRpRs8Vdr0RtxOHDh7Fq1Sp8/vnnsLOzg1Qqxeeff45jx45h3bp1YpdH1Gxxi5KIiMgEblESERGZwKAkIiIygUFJRERkAoOSiIjIBAYlERGRCQxKIiIiExiUREREJjAoiYiITGBQEhERmcCgJCIiMoFBSUREZAKDkoiIyIT/B2h4ylL307quAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 500x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import arange, exp\n",
    "\n",
    "x = arange(-10,11,0.5)\n",
    "y = 1 / (1 + exp(-x))\n",
    "\n",
    "fig1 = plt.figure(figsize=[5,2.5])\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"S(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefits of the sigmoid function are: (i) its output lies between $0$ and $1$, and (ii) its derivative has a simple form (and therefore is relatively quick to compute):\n",
    "\n",
    "$$S'(x) = \\frac{dS(x)}{dx} = S(x) \\, [1 - S(x)].  \\hspace{6em}  [3]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The ***ReLU*** (Rectified Linear Unit) function, often used in deep learning networks: \n",
    "\n",
    "$$f(x) = \\textrm{max(0, x)} = \n",
    "\\begin{cases}\n",
    "  0, & x \\le 0 \\\\\n",
    "  x, & x > 0.\n",
    "\\end{cases}\n",
    "\\hspace{5em}  [4]$$\n",
    "\n",
    "Execute the next code cell to see a plot of ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'ReLU(x)')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [-5,-4,-3,-2,-1,0,1,2, 3, 4, 5]\n",
    "y = []\n",
    "  \n",
    "for i in range(len(x)):\n",
    "    y.append(max(0,x[i]))\n",
    "  \n",
    "fig2 = plt.figure(figsize=[5,2.5])\n",
    "plt.plot(x, y, color='green') \n",
    "plt.xlabel('x') \n",
    "plt.ylabel('y') \n",
    "plt.title(\"ReLU Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ReLU(x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the ReLU function's derivative,\n",
    "\n",
    "$$\\frac{df(x)}{dx} = \n",
    "\\begin{cases}\n",
    "  0, & x \\le 0 \\\\\n",
    "  1, & x > 0,\n",
    "\\end{cases}  \\hspace{9em}  [5]$$\n",
    "\n",
    "which is just a ***step function***, is even simpler than that of the sigmoid function, and therefore quicker to use in computations.  \n",
    "\n",
    "The simplicity of the two derivatives is important in connection with how the network \"learns.\"  Since deep learning networks can have many layers with many neurons in each, and since the derivative of the activation function will be used in multiple cycles (maybe thousands, or even more) of the learning procedure, speed of computation is an important consideration.  (For the same reason, sometimes $\\tanh(x)$ is used as the activation function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will use the ReLU activation function for the neurons in the hidden layers, but it turns out that neither the ReLU nor the sigmoid activation function is optimal for the output layer in this digit classification problem.  Instead, our NN will use what the PyTorch package calls the **`LogSoftmax`** activation function, defined in terms of the ***Softmax*** function, $\\sigma(x_i)$, as follows:\n",
    "\n",
    "$$ \\sigma(x_i) \\equiv \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)},  \\hspace{12em} [6]$$\n",
    "$$ \\textrm{LogSoftmax}(x_i) \\equiv \\log \\left( \\sigma(x_i) \\right) = \\log \\left( \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)} \\right),  \\hspace{1em} [7]$$\n",
    "\n",
    "where the $x_j$ are the inputs to the output layer.  The Softmax function is a generalization of the sigmoid function appropriate for vectors of inputs rather than single inputs.  Note that because of the normalizing sum in the denominator, the value of $\\sigma(x_i)$ will lie between $0$ and $1$.  Furthermore, $\\sum_i \\sigma(x_i) = 1$, so that the terms on the right of [6] can be interpreted as probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"green\"><b>Breakpoint 1</b></font>: Confirm expression [3] for $S'(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's one more piece to the standard NN model: each neuron (after the input layer) has a ***bias***, which acts as a threshold for its activation.  Denoting the bias for the $j^{\\textrm{th}}$ neuron in a layer as $b_j$ then, with $y_j$ (as given in [1]) the *input* to the $j^{\\textrm{th}}$ neuron, its *output* would be\n",
    "\n",
    "$$\\tilde{y}_j = F(y_j +b_j) = F \\left( \\sum_i w_{ji} x_i + b_j \\right),  \\hspace{4em}  [8]$$\n",
    "\n",
    "where $F$ is either the sigmoid function or the ReLU function (or, in certain applications, possibly another function).  This form implies that the output of the neuron with a ReLU activation function will be non-zero only if $\\sum_i w_{ji} x_i + b_j > 0$, or $\\sum_i w_{ji} x_i > -b_j$ (so, actually, $-b_j$, not $b_j$, is a threshold which the weighted sum of inputs must overcome to produce a nonzero output).  The bias effectively shifts the activation functions to the right or left in the plots above, depending on whether it is positive or negative.  (Note that a bias can be considered as another weight multiplying a fixed activation $x = 1$, so biases usually are included together with the weights in combined weight-bias vectors.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is continued layer by layer through the network from the input layer to the output layer: the inputs to the neurons of each  new layer in the sequence are the weighted sums of the outputs from the neurons of the previous layer, as in [1], and the outputs of the neurons in the new layer are computed from that weighted sum and the biases using an activation function, as in [8].  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might be helpful to think of the NN as implementing a function that's an approximation to a desired one.  (In fact, there's a ***universal approximation theorem*** that says that under broad conditions a feedforward network can approximate almost any function one is likely to deal with.)  A simple example would be a network that seeks a linear best fit to a set of data.  The network in that case is trying to determine the optimal values for the relevant adjustable parameters -- the slope and y-intercept -- to best fit the data.  Of course, if the data doesn't all lie on a single line, the linear best fit will not exactly match all of the data points. \n",
    "\n",
    "In the digit classification case, the desired function would match each input image showing a digit to a unique activated neuron in the output layer.  In this case, the adjustable parameters are the weights and biases.  In a neural network, the approximate function implemented by the network will result in multiple neurons in the output layer being activated, but with one neuron activated significantly more than the others.  (This is the analogue of the linear fit not passing through all data points if they don't lie on a line.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be a good time to watch the next video in the 3Blue1Brown series: <a href=\"https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=2\">3Blue1Brown: Gradient descent - how neural networks learn | Chapter 2</a>, which previews the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">16.1.3 The Learning Process</font>\n",
    "\n",
    "So how does a NN learn?  By changing its weights and biases!  \n",
    "\n",
    "The changes to be made are determined by providing ***training*** data sets to the network, for which the desired result is known.  For example, in the digit classification problem we would provide lots of images of handwritten \"$0$\"s, and compare the network's output with the desired output -- only the output neuron corresponding to $0$ being activated.  Then we do similarly for \"$1$\"s, \"$2$\"s, and so on, up through \"$9$\"s.  (The use of training data to help \"teach\" the model marks digit classification as an example of a ***supervised learning*** problem.  In other machine learning tasks, networks can learn for themselves what the important features of a data set are without having to be trained by a separate data set.)\n",
    "\n",
    "We next introduce something called the ***loss function*** (sometimes ***cost function*** or ***objective function***), which measures the difference between the network's *actual* outputs for the training inputs and the *desired* outputs.  The weights and biases then are modified so as to *minimize the loss function*.\n",
    "\n",
    "To be rigorous, let's introduce the following notation: $z$ is a training input, $y(z)$ is the *desired* output for that input (i.e., the vector of outputs of the neurons in the output layer), $a$ is the actual output (also a vector), and $W$ and $B$ are the *sets* of weights and biases in the network, respectively.  Then, one example of a loss function $C$, considered as a function of the weights and biases, is \n",
    "\n",
    "$$C(W, B) = \\frac{1}{N} \\sum_z \\| y(z) - a \\|^2,  \\hspace{7em} [9]$$\n",
    "\n",
    "where $N$ is the number of training inputs, the sum is over all the training inputs, and the $\\|$ symbol indicates the vector norm of the value $y(z) - a$, since both terms are vectors.  \n",
    "\n",
    "The $1/N$ factor multiplying the sum means that we're finding an average value of the squared quantity.  Note that this average of squared differences is essentially the (***population***) ***variance*** from statistics, which you might have seen in statistical mechanics or quantum mechanics.  This example loss function is easy to understand and may be familiar, but it is not always the best choice.  \n",
    "\n",
    "> **Note:** Constructing the most effective neural network for a particular task generally involves quite a bit of trial and error with different loss and activation functions until one finds a combination that provides the desired accuracy when the network is run on test inputs.  It's as much art as science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you might want to look at the next video in the 3Blue1Brown series: <a href=\"https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3\"> 3Blue1Brown: What is backpropagation really doing? | Chapter 3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Backpropagation and Stochastic Gradient Descent</font>\n",
    "\n",
    "Because $C$ is a function of (a large number of) weights and biases, we can imagine it as defining a surface in some very high-dimensional space whose coordinate axes are the various weights and biases.  Ideally, we'd like to find the ***global minimum*** -- the lowest value of the function, corresponding to the lowest \"valley\" in the surface.  The coordinates of the point in that multidimensional space corresponding to that lowest function value would be the values of the weights and biases that minimize the loss function.  \n",
    "\n",
    "We know from calculus that to find the minimum of a function of one variable, $f(x)$, we just take the derivative with respect to $x$ and set it equal to zero to find the value of $x$ corresponding to a minimum (or possibly a maximum or inflection point) of the function.  To do that with the loss function, which can depend on hundreds, thousands, or even more variables (with respect to which the derivatives all would have to vanish), would be extremely difficult, in general.  (Note that this effort wouldn't even necessarily find the global minimum.)  So, we need a more computationally-manageable approach.\n",
    "\n",
    "In practice, it's generally very hard to find the global minimum, and the learning process just tries to find a ***local minimum*** (*any* valley, not necessarily the lowest one).  A common algorithm used to do this is called ***stochastic gradient descent*** (SGD).  It's based on the fact that, at any point on a surface, the gradient points *up* along the direction in which the slope is the steepest.  The opposite direction of the gradient would point the fastest way *down* the surface, analogous to the direction a ball would roll down a hill in the presence of gravity.  That's the direction in which we want to change the weights and biases at any point in the process in order to work our way down to a valley, thereby minimizing the loss function and making the actual output of the NN close to the desired output.\n",
    "\n",
    "The \"stochastic\" part of SGD refers to the fact that, in order to further reduce the amount of computation required for training, the gradient descent process is applied not to the *complete* loss function involving *all* the training examples (as in [9]), but to an *approximate* loss function computed from a *randomly chosen subset* of the training examples, called a ***minibatch***.  \n",
    "\n",
    "Label the training examples as $z_1, z_2, \\ldots, z_M$, and then \n",
    "\n",
    "$$C \\approx C_{z_j} \\equiv \\frac{1}{M} \\sum_{z_j} \\| y(z_j) - a \\|^2, \\hspace{6.5em} [9]$$\n",
    "\n",
    "where the sum is over the $M$ members $z_j$ of the minibatch.  This process is repeated with multiple minibatches in order to get a better approximation to the loss function.\n",
    "\n",
    "If, using a simplified notation for the weights, we denote them as $w_k$, the SGD approach says the new weights and biases (indicated by primes) are\n",
    "\n",
    "$$w_k' = w_k - \\frac{\\eta}{M} \\sum_j \\frac{\\partial C_{z_j}}{\\partial w_k},  \\hspace{9em} [10]$$\n",
    "$$b_k' = b_k - \\frac{\\eta}{M} \\sum_j \\frac{\\partial C_{z_j}}{\\partial b_k},  \\hspace{9.5em} [11]$$\n",
    "\n",
    "where the $z_j$ are the members of the mini-batch, with $M$ members; $C_{z_j}$ is the loss function computed from that mini-batch; and $\\eta$ is the ***learning parameter*** which is used to \"scale\" the size of the steps taken opposite the direction of the gradient (larger $\\eta$ means larger steps).  The value of $\\eta$ is determined, basically by trial and error, by the person training the network.  \n",
    "\n",
    "Equations [10] and [11] tell us that each weight or bias is changed by an amount proportional to the average partial derivative of $C$ with respect to that weight or bias (where the average is taken over the members of the training subset).  The `-` signs make sense: if the loss function *increases* when a particular weight is increased, so that $\\partial C_{z_j} / \\partial w_k > 0$, then we want to *decrease* that weight, i.e. change it by a *negative* amount.  The `-` sign makes that happen.\n",
    "\n",
    "This process of using the outputs of the NN (as incorporated in the loss function) to go back and change the weights and biases is called ***backpropagation***.  As noted in the video preceding this subsection, the process proceeds backwards through the network, updating the weights and biases sequentially for layers earlier and earlier in the network.  Another nice visualization of the process is provided here: https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll .  \n",
    "\n",
    "It's important to note that there are other algorithms besides stochastic gradient descent for finding the minimum of the loss function.  The three Python packages discussed in this module each offer multiple options; which are called ***optimizers*** in neural network lingo.\n",
    "\n",
    "For best results, the backpropagation algorithm is repeated many times with different training subsets.  Each cycle of computation using a new subset is called a training ***epoch***.  \n",
    "\n",
    "The discussion in this subsection has provided only an overview of the backpropagation process.  For all the gory details, see <a href=\"https://neuralnetworksanddeeplearning.com\"> Neural Networks and Deep Learning</a> or a textbook on neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The definitions of the various loss functions, optimizers, and activation functions available in the various NN packages tend to be fairly technical, and most are beyond the scope of this module.  See each package's documentation for the details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Outline'>Back to the Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">Please execute the cell below.  The code in it will be used to highlight certain key cells later in the notebook.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_background(color):         \n",
    "    script = (\"var cell = this.closest('.code_cell');\"\n",
    "              \"var editor = cell.querySelector('.input_area');\" \n",
    "              \"editor.style.background='{}';\" \"this.parentNode.removeChild(this)\"     \n",
    "             ).format(color)      \n",
    "    display(HTML('<img src onerror=\"{}\">'.format(script)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">16.2 PyTorch</font>\n",
    "\n",
    "(This section is adapted from https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627.)\n",
    "\n",
    "The process described above for implementing a neural network can be coded from scratch, but that's obviously a lot of work.  (See the section titled \"Implementing our network to classify digits\" in <a href=\"https://neuralnetworksanddeeplearning.com/chap1.html\"> Neural Networks and Deep Learning, Chapter 1</a>.)  As mentioned at the top of this module, Python libraries have been developed to do the vast majority of the computations automatically, streamlining the process greatly.  Here we look at one of the two main libraries for doing these computations -- **`PyTorch`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyTorch` actually has two main purposes:\n",
    "1. It's a replacement for `numpy` designed to make use of a computer's GPUs -- its Graphics Processing Units.\n",
    "2. It's a fast, flexible library for constructing deep learning models.\n",
    "\n",
    "Item 1 is important because GPUs -- hardware elements that provide the data for display on a computer screen -- are designed to perform matrix operations very efficiently, since those operations are key to computing pixel values for on-screen graphics.  (The image on a screen is just a matrix of pixel values.)  Since neural network learning also is based on matrix operations, as noted following Eqs. [1] & [9], GPUs are highly suited to this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four key sublibraries of `PyTorch` used to implement the various parts of the NN design process: \n",
    "- `torch.utils`, specifically its sublibrary `torch.utils.data`, is used to import the data for the network to analyze.\n",
    "- `torch.nn` provides the functions for designing the network; i.e., for specifying the number of layers, the loss function, the activation function, etc. \n",
    "- `torch.autograd` contains the functions for computing the gradient.\n",
    "- `torch.optim` has the functions for implementing the backpropagation learning procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">16.2.1 PyTorch Tensors</font>\n",
    "\n",
    "The basic mathematical object used by `PyTorch` is a ***tensor***, very similar to a `numpy` array.  They can be constructed with any number of dimensions.  A few examples are shown in the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = tensor(5.)\n",
      "B = tensor([2., 4., 6., 8.])\n",
      "C =\n",
      " tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.tensor(5.0)\n",
    "print(\"A =\", A)\n",
    "\n",
    "B = torch.tensor([2.0, 4.0, 6.0, 8.0])\n",
    "print(\"B =\", B)\n",
    "\n",
    "C = torch.tensor([[2.0, 4.0], [6.0, 8.0]])\n",
    "print(\"C =\\n\", C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **.shape** method, also seen for `numpy`, will give the dimensions of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([4])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(B.shape)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `A`, which contains a single element, has no dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and slicing work for tensors just as for `numpy` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = \n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) \n",
      "\n",
      "Element in first row, second column:\n",
      " tensor(2) \n",
      "\n",
      "Second row:\n",
      " tensor([4, 5, 6]) \n",
      "\n",
      "Third column:\n",
      " tensor([3, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "F = torch.tensor([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\n",
    "print(\"F = \\n\", F, \"\\n\")\n",
    "\n",
    "print(\"Element in first row, second column:\\n\", F[0,1], \"\\n\")\n",
    "print(\"Second row:\\n\", F[1,:], \"\\n\")    \n",
    "print(\"Third column:\\n\", F[:,2])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types contained in a tensor can be obtained using the **`.dtype`** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(C.dtype)\n",
    "print(F.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see that tensor `C` contains (32-bit) floats, while `F` contains (64-bit) integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, `numpy` arrays can be converted to `pytorch` tensors using **`torch.from_numpy()`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tA = \n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "nA = array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "tA = torch.from_numpy(nA)\n",
    "print(\"tA = \\n\", tA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors *of the same shape* can be added and subtracted using **`+`** and **`-`**, respectively.  A tensor can be multiplied by a scalar using **`*`**, and it can be divided by a scalar using **`/`**.  \n",
    "\n",
    "Multiplication of two tensors *of the same shape* using **`*`** gives element-by-element multiplication, while **`/`** gives element-by-element division.\n",
    "\n",
    "The usual matrix multiplication is performed using the function **`mm`** with the syntax `torch.mm(tensor1, tensor2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">16.2.2 Digit Classification Network</font>\n",
    "\n",
    "(This subsection is adapted from https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627?gi=fe8d54d023a4 , by Amitrajit Bose.)\n",
    "\n",
    "In this example, we perform the following sequence of tasks to implement a digit classification network:\n",
    "\n",
    "- Load Data\n",
    "- Define a PyTorch ***model***: a network with the number and sizes of hidden layers, the activation functions, and the loss function specified.\n",
    "- Define a loss function and backpropagation rules.  The backpropagation rules specify what loss function optimizer will be used.\n",
    "- Run a training cycle\n",
    "- Evaluate the model\n",
    "\n",
    "It's worth pointing out that the code below will be unlike that in previous modules, where you usually created your own functions to implement algorithms.  As noted earlier, we're not taking a \"from scratch\" approach here.  The goal is to learn to make use of the functions built in to the PyTorch and (later) TensorFlow & scikit-learn packages.  Most of this kind of coding consists of stringing together package functions in an appropriate sequence of function calls.  This represents a higher-level approach to programming than you've seen previously in the modules.  It may be less satisfying than that previous programming in the sense that the package functions essentially are \"black boxes\" to which you as the user simply provide the appropriate arguments -- not necessarily knowing exactly why or what the function is doing -- but this is how a lot of scientific programming goes.  We have to trust that the designers of the package functions have done their jobs properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Importing Packages</font>\n",
    "Although `torch` was imported in an earlier code cell, we do it again here to have all the needed steps included in this example.  We also import `numpy`, `matplotlib` for plotting, some `torch` subpackages, and a package (with subpackages) called **`torchvision`**, which helps with loading and manipulating images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Loading and Formatting Data</font>\n",
    "Next, we'll load a dataset.  The standard set of images of digitized handwritten numbers is maintained in the MNIST (Modified National Institute of Standards and Technology) database.  That database includes 60000 images meant to be used as a training set, and another 10000 images meant to be used to test a neural network once it has been trained.  Each of the training images has a *label* associated with it that identifies the digit it displays.\n",
    "\n",
    "Before loading the images, we want to provide a specification for `torchvision` of how to transform the images so that they're useful for us.  Each MNIST file for the image of a digit actually includes *three* arrays of data, representing the separate intensities of red, blue, and green pixels in the image.  We will want to separate those three \"color channels,\" and force the ranges of intensity in the channels to be the same.  That's accomplished by this standard line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`transforms.ToTensor()`** function will pull out the color channels from each image file.  Then it will convert the pixels of each color \"sub-image\" so that its brightness range lies between 0 (pure black) and 1 (maximum color \"saturation\"). The resulting images will be `torch` tensors.\n",
    "\n",
    "**`transforms.Normalize()`** further adjusts the image tensors so that their mean and standard deviation of intensity have the values specified (0.5 for both, in this example; these are not set in stone).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the data sets: first the training sets, then the test sets.  In each case, two lines of code are involved.  The first line specifies where to find the MNIST sets (in the MNIST `'.data'` directory) and whether to get the training or test sets.   Then, it applies the transformations above (`transform=transform`).  The second line actually does the downloading, putting the digit images in minibatches of size specified by `batch_size`.  (`shuffle=True` causes the image files to be randomly shuffled as they're put into minibatches.)  Note that once you have downloaded the images to a given directory on a given computer, they won't be downloaded again unless the destination directory is changed; in the code below, the destination directory is labeled `data`, located within the directory where this module is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Download and transform training sets (note train=True)\n",
    "train_set = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True)\n",
    "\n",
    "# Download and transform test sets (note train=False)\n",
    "test_set = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, shuffle=True)\n",
    "\n",
    "print(train_set.data.size())\n",
    "print(test_set.data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first `print` statement produced `torch.Size([60000, 28, 28])`, confirming that we have 60000 images, each of size 28 x 28 pixels, and the second `print` statement produced `torch.Size([10000, 28, 28])`, confirming that we have 10000 images with the same dimensions as the training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a look at some images using the code below.  The first line (using the Python `iter` function) basically identifies a counter for the `train_loader` set of images; i.e., the first image has a counter of `0`, the next has `1`, etc.  The second line gets the image (and the label indicating which numerical digit it displays) associated with the next value of the iterator.  The following set of lines will print the 10 images as subplots in grayscale, by looping through the set of images.  If you rerun the cell, you'll get the images in a different mini-batch each time.  (The `.numpy().squeeze()` part removes the label from the figure.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16940\\3391650848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Print a batch as subplots\n",
    "figure = plt.figure(figsize=[5, 3])\n",
    "num_images = 10\n",
    "for index in range(0, num_images):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the printout from `print(images.shape)`: `torch.Size([10])`, reflecting the `10` labels for the mini-batch.  Also, the output from `print(images.shape)` is `torchSize([10, 1, 28, 28])`.  The `10` is for the size of the mini-batch, the `1` is for the labels, and, again, `28, 28` indicates the pixel dimensions of each image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Building the Network</font>\n",
    "\n",
    "Now we can build the network.  The input layer will have 28 x 28 = 784 neurons, and we'll use two hidden layers, of sizes 128 and 64 neurons, successively.  The output layer will, of course, have 10 neurons to indicate the digits 0-9.  \n",
    "\n",
    "The **`nn.Sequential`** function lets us specify and connect the layers, as shown in the next code cell.  \n",
    "\n",
    "(**Note:** the first line of the cell below, which reappears in some later cells, just changes the cell background color.  It is not part of the process of building a neural network!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#FFFF66';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (5): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "set_background('#FFFF66')    # ignore this line\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]), nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]), nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size), nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each **`nn.Linear`** function connects one layer to the next and specifies the activation function to use for each layer: the first `nn.Linear` function connects the input layer, with size `input_size`, to the first hidden layer, with size `hidden_sizes[0]`, and uses the `ReLU` activation function; the second `nn.Linear` function connects the first hidden layer, with size `hidden_sizes[0]`, to the second hidden layer, with size `hidden_sizes[1]`, and again uses the `ReLU` activation function.  The third `nn.Linear` function connects the last hidden layer with the output layer, and uses the `LogSoftmax` activation function.\n",
    "\n",
    "The name `Linear` in `nn.Linear` comes from the fact that this function applies the linear transformation of [1] (with the option to include biases, as in [6]) to compute inputs to neurons.  There are other transformations, as well as other activation functions and other types of neural network structures, available in the `torch.nn` package.  See https://pytorch.org/docs/stable/nn.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is for us to specify the loss function for the network to use.  It turns out that while the ***mean-square error*** loss function shown in [7] is good for simple problems, e.g. finding the best-fit curve to a one-dimensional set of data of the form $y = f(x)$, it's not so good for multidimensional classification problems like the one considered here.  It is, however, related to a better loss function for the digit classification application -- the ***negative log likelihood*** loss function.  The PyTorch name for this loss function is `nn.NLLLoss`, so we need..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#FFFF66';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background('#FFFF66')   # ignore this line\n",
    "\n",
    "criterion = nn.NLLLoss()    # use negative log likelihood as loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the training images and reshape them into vectors, supply them to the model, and compute the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images = images.view(images.shape[0], -1)    # reshape images into 784-element vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next supply the reshaped images to the model, compute the loss function, and specify how we want to minimize the loss function.  We're going to use steepest gradient descent (`optim.SGD`) and a learning rate (`lr`), i.e. $\\eta$, of `0.01`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.code_cell');var editor = cell.querySelector('.input_area');editor.style.background='#FFFF66';this.parentNode.removeChild(this)\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_background('#FFFF66')    # ignore this line\n",
    "\n",
    "\n",
    "mod = model(images)                                     # supply the images to the model \n",
    "\n",
    "loss = criterion(mod, labels)                           # calculate the loss\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)    # specify optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are other loss functions beside negative log likelihood, and many alternatives to SGD for minimizing the loss function, available in PyTorch.  See the documentation at https://pytorch.org/docs/stable/index.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Training the Network</font>\n",
    "\n",
    "Putting everything together, to do the training we execute the loop below.  First, the `time` package is imported and we store the starting time (as `time0`) so that we can determine how long each training epoch takes.  The number of training epochs is specified by `epochs`. \n",
    "\n",
    "Now we loop over the training epochs, setting the loss function to zero as the starting point for each one.  `running_loss` stores the value of the loss function.  Within that loop, we loop over images in the training set, first reshaping each one into a vector and setting the gradients to zero, then applying the model specified above by `nn.Sequential` to the image and computing the loss function.  Next, backpropagation is applied to update the weights, and the change in the loss function is recorded.  \n",
    "\n",
    "At the end of each training epoch, the first of the `print` statements displays the value of the loss function normalized by the number of minibatches in the training set (in this case, with minibatches of 10 images, the number of minibatches is 60000/10 = 6000), and the second `print` statement prints out the cumulative time elapsed in the training process.\n",
    "\n",
    "Once you execute the next cell, the training process will run.  Nothing will happen for the first 20-30 seconds until the first training epoch is completed and the `print` statements are executed.  (Of course, the time it takes for each epoch depends on what machine this notebook is run on and what other tasks it is running.)  The entire training process will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 -- Training loss: 0.440555\n",
      "  Training Time (in minutes) = 0.273\n",
      "\n",
      " Epoch 2 -- Training loss: 0.204027\n",
      "  Training Time (in minutes) = 0.578\n",
      "\n",
      " Epoch 3 -- Training loss: 0.148021\n",
      "  Training Time (in minutes) = 0.864\n",
      "\n",
      " Epoch 4 -- Training loss: 0.118085\n",
      "  Training Time (in minutes) = 1.164\n",
      "\n",
      " Epoch 5 -- Training loss: 0.098500\n",
      "  Training Time (in minutes) = 1.437\n",
      "\n",
      " Epoch 6 -- Training loss: 0.084786\n",
      "  Training Time (in minutes) = 1.788\n",
      "\n",
      " Epoch 7 -- Training loss: 0.073960\n",
      "  Training Time (in minutes) = 2.089\n",
      "\n",
      " Epoch 8 -- Training loss: 0.065477\n",
      "  Training Time (in minutes) = 2.396\n",
      "\n",
      " Epoch 9 -- Training loss: 0.058478\n",
      "  Training Time (in minutes) = 2.676\n",
      "\n",
      " Epoch 10 -- Training loss: 0.052652\n",
      "  Training Time (in minutes) = 2.941\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "time0 = time()         # to time the process\n",
    "epochs = 10            # number of training epochs\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0   # keeps track of value of loss function\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()              # set gradients to zero initially\n",
    "        \n",
    "        output = model(images)             # apply the model to the image\n",
    "        loss = criterion(output, labels)   # compute the loss function\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()                    # compute gradients of loss function\n",
    "        \n",
    "        # Optimize weights \n",
    "        optimizer.step()                   # use gradients to update weights\n",
    "        \n",
    "        running_loss += loss.item()        # update loss function value\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n\", \"Epoch %d -- Training loss: %8.6f\" %(e+1, running_loss/len(train_loader)))\n",
    "        print(\"  Training Time (in minutes) = %5.3f\" %((time() - time0) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The yellow-highlighted cells above represent the key steps in *constructing* our neural network model.  The other code cells serve either as preparatory steps or for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Testing the Network</font>\n",
    "\n",
    "Now it's time to test our model!  First, we have to load the test images stored earlier in the variable `test_loader`.  Then we again use the `next` function to separate them into images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter_test = iter(test_loader)\n",
    "images_test, labels_test = next(dataiter_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can display some of those images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 350x250 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure1 = plt.figure(figsize=[3.5, 2.5])\n",
    "num_images = 10\n",
    "for index in range(0, num_images):\n",
    "    plt.subplot(2, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images_test[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run the model on a test image.  We show the first test image, then reshape it to a vector and run the model on it.  Since, as noted above, the Softmax function computes probabilities, but our final activation `LogSoftmax` computes the logs of those probabilities, we need to exponentiate the network outputs to get back to probabilities.  Finally, we print out and also plot a bar chart of the probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALIAAACyCAYAAADmipVoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAFrUlEQVR4nO3dsUsbbxzH8SfhV1QwSV0UYgLOakGdHKQ6FEVTWnASuhQXcSyFImKdBP8AQXExQymlFXQpDQrOdtN2KaUUC7GhiBBMtg6531SH3/NcezlNf+Zz79f49cnlhjcP3pmcMc/zPAM0ufj/fQLAdSBkSCBkSCBkSCBkSCBkSCBkSPgn7AtrtZoplUomkUiYWCx2necEXPI8z1SrVZNOp0087r/vhg65VCqZbDYb9uVAXYrFoslkMr4/Dx1yIpG4fINkMhn2MMBvVSoVk81mL3vzEzrkX79OJJNJQkbD/enXVy72IIGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQIYGQISH0A1pUfP782Tm/e/euNZuennau7ejoCPx+Y2Nj1mx8fDzw6+HGjgwJhAwJhAwJhAwJhAwJsbD/+bRSqZhUKmUuLi6a+rGyhULBOZ+ammrI+926dcuaPXv2zLl2ZWWlIefQTIJ2xo4MCYQMCYQMCYQMCZG/2Ds9PXXO19bWrNnu7m7g45bLZef8/PzcmrW1tTnX7u/vW7ORkZHA56CAiz1ECiFDAiFDAiFDAiFDQuTvWjTKp0+fnPPe3t7Ax8jn89bs8ePHYU+pKXHXApFCyJBAyJBAyJAQ+W9RX4fv379bs4WFhcCv9/sW9r1790KfU9SwI0MCIUMCIUMCIUMCIUMCdy3q4Pch/FwuZ80+fvwY+Lh9fX3OeSaTCXyMqGNHhgRChgRChgRChgQu9nwUi0Vrtrq66lxbz4Xd4OCgNdvZ2Ql+YnBiR4YEQoYEQoYEQoYEQoaEyN+1ePv2rXO+tLRkzT58+HDl93v06JE1Ozg4cK6dmZm58vtFBTsyJBAyJBAyJBAyJETqkVnv37+3ZqOjo861P3/+bPTpXIrH3ftJZ2dn4GM8efLEmvn9t6hmwiOzECmEDAmEDAmEDAmEDAmRumvx7ds3a+b3jLbXr19bs/n5eefa27dvBz4Hvw/nX5XrzsedO3eca/f29qxZV1fXtZ/TdeCuBSKFkCGBkCGBkCEhUhd7zcb1Wennz5871x4fHwc+7tHRkTUbGBgI/Pq/iYs9RAohQwIhQwIhQwIhQ0Lkv0V9k92/f9+adXd3O9cODQ01+nRuNHZkSCBkSCBkSCBkSOBir8n4PeIr6tiRIYGQIYGQIYGQIYGQIYG7FjdAuVx2zufm5qzZ4eFh4ONOTk465z09PYGP0SzYkSGBkCGBkCGBkCGBi72/zPXYrvX1defa7e3twMft7++3Zi9fvnSurecRX82CHRkSCBkSCBkSCBkSCBkSuGvRIF+/fnXOFxcXrdmbN28CH3dwcNA5X15etmYdHR2Bj9vs2JEhgZAhgZAhgZAhgYu9OpycnDjnGxsb1uzFixfOtT9+/LBmra2tzrWbm5vW7MGDB861in92rgc7MiQQMiQQMiQQMiQQMiRE6q6F647Bu3fvnGu3tras2ZcvX5xrz87OAp/D8PCwNXv16pVzreK3nRuFHRkSCBkSCBkSCBkSJC/28vm8c/706VNr5ve4qnq4/o/zwsKCc20ul7Nm7e3tVz6HqGNHhgRChgRChgRChgRChgTJuxaFQsE5r+cOxezsrDWbmJhwrn348KE1a2lpCfxeuDp2ZEggZEggZEggZEiQvNir5xFU0MCODAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmEDAmhP4/seZ4xxphKpXJtJwP816++fvXmJ3TI1WrVGGNMNpsNewggsGq1alKplO/PY96fUvdRq9VMqVQyiUTCxGKx0CcI/I7neaZarZp0Om3icf/fhEOHDNwkXOxBAiFDAiFDAiFDAiFDAiFDAiFDAiFDAiFDAiFDAiFDAiFDwr+BUk08CIx0NgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 250x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig2, ax2 = plt.subplots(figsize=[2.5,2.0])\n",
    "plt.imshow(images_test[0].numpy().squeeze(), cmap='gray_r')   # show the first image in test set\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the model on all the image and get the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probabilities of this image being the digits 0-9 are:\n",
      "|     0     |     1     |     2     |     3     |     4     |     5     |     6     |     7     |     8     |     9     |\n",
      "| 5.678e-09 | 3.860e-05 | 5.596e-10 | 9.997e-01 | 1.356e-08 | 2.231e-04 | 3.873e-09 | 3.567e-06 | 5.005e-10 | 2.683e-06 |\n",
      "\n",
      "PREDICTED DIGIT = 3 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 10.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 300x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images_test[0].view(1, 784)   # reshape first image in test set\n",
    "\n",
    "with torch.no_grad():               # run the model on the image without computing gradients\n",
    "    mod = model(img)                # probabilities from output layer\n",
    "    \n",
    "ps = torch.exp(mod)                 # exponentiate outputs to undo \"log\" in logSoftmax to get probabilities \n",
    "probab = list(ps.numpy()[0])        # probabilities that image represents each digit 0 --> 9\n",
    "\n",
    "digits = list(range(10))\n",
    "print(\"The probabilities of this image being the digits 0-9 are:\")\n",
    "print(\"| {:^9d} | {:^9d} | {:^9d} | {:^9d} | {:^9d} | {:^9d} | {:^9d} | {:^9d} | {:^9d} | {:^9d} |\".format(*digits))\n",
    "print(\"| {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} | {:^.3e} |\\n\".format(*probab))\n",
    "print(\"PREDICTED DIGIT =\", probab.index(max(probab)), \"\\n\")   # print digit corresponding to maximum probability\n",
    "\n",
    "digits = range(0,10)                # x-axis labels for bar chart\n",
    "fig3, ax3 = plt.subplots(figsize=[3.0, 2.0])\n",
    "plt.bar(digits, probab)\n",
    "plt.title(\"Probabilities of Image Matching the Digits 0-9\")\n",
    "ax3.axis([0,10,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particular image analyzed above, and therefore the digit identified by the network, will depend on how this notebook was run, but the digit most likely will be identified properly, with >99.9% probability, while the probabilities for the wrong digits will be *much* smaller.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, getting a single image right doesn't mean our network is effective.  Let's check all the other test images.  (Evaluating the model will be *much* quicker than training it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000 \n",
      "\n",
      "MODEL ACCURACY = 98.04 %\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "all_count = 0\n",
    "\n",
    "# Loop through test images\n",
    "for images, labels in test_loader:\n",
    "    for i in range(len(labels)):\n",
    "        img = images[i].view(1, 784)            # reshape next image to vector\n",
    "        with torch.no_grad():                   # do not compute gradients\n",
    "            logps = model(img)                  # run network on image\n",
    "    \n",
    "        ps = torch.exp(logps)                   # exponentiate outputs to get probabilities\n",
    "        probab = list(ps.numpy()[0])            \n",
    "        \n",
    "        pred_label = probab.index(max(probab))  # image digit based on highest probability output\n",
    "        true_label = labels.numpy()[i]          # actual digit from label\n",
    "        if(true_label == pred_label):\n",
    "            correct_count += 1                  # digit is classified correctly\n",
    "        all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count, \"\\n\")\n",
    "print(\"MODEL ACCURACY =\", (correct_count/all_count)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you train for 10 or more epochs, you should get more than 9700 out of 10000 images classified correctly.  That's pretty impressive considering that only two hidden layers were used, and we might not have used the optimal network structure, activation functions, or loss function.  \n",
    "\n",
    "The best digit classifiers apparently have an accuracy of 99.8% (as of early 2023), so our network is not far off.  You might want to try tweaking some of the parameters -- the sizes of the hidden layers, the learning rate, the number of training epochs -- to see whether you can improve the network's performance.  (You also could change the activation functions, the loss function, or the number of hidden layers, or any combination of all these network characteristics.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Saving and Loading a Model</font>\n",
    "\n",
    "Now that the testing has finished, let's save our model.  (This could have been done before testing.)  This will allow us to use it on other images without having to repeat the training process we went through.  \n",
    "\n",
    "The code to save the model (named `model` by the `nn.Sequential` command in an earlier highlighted code cell) with the file name `mnist_digit_classification.pt` in the same directory as this notebook is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./mnist_digit_classification.pt\"   # the directory and filename to save under\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To emphasize: this has saved the *model* (not the notebook) with all its weights and biases determined by the training process.  The `./` part of the `PATH` variable just specifies the directory in which this notebook resides; the rest of `PATH` is the file name.  Note that the `PATH` does not need to be specified separately; it can just be typed as the second input in `torch.save`.\n",
    "\n",
    "Also note that PyTorch models usually are saved with `.pt` or `.pth` extensions.  \n",
    "\n",
    "To load a model into a notebook, use the syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (5): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = torch.load(PATH)\n",
    "model1.eval()               # display the structure of the loaded module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name `model1` is used here simply to reflect the fact that the re-loaded model does not need to have the same name as the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Outline'>Back to the Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">16.3 TensorFlow</font>\n",
    "\n",
    "(This section adapted from https://www.TensorFlow.org/tutorials/keras/classification .)\n",
    "\n",
    "Like PyTorch, ***TensorFlow*** is a large library of machine learning functions with lots of flexibility.  ***Keras*** is a kind of add-on library to TensorFlow with high-level functions that make building machine learning systems easier for beginners. \n",
    "\n",
    "Start by importing the `tensorflow` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import the MNIST data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(len(train_labels))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `print` statments show that the training and test sets have the dimensions we expect: the `_images` sets of images are 28 x 28; the `_labels` sets of labels are just 1-D vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we normalize the pixel values to the range [0, 1] by dividing by the maximum value of 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the model (discussed below the code cell):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_background('#FFFF66')    # ignore this line\n",
    "\n",
    "modelK = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, the `model` is defined using `tf.keras.models.Sequential`, with layer sizes and activation functions specified.  ReLU is used for the hidden layers, as in the PyTorch model.  It turns out that we don't need a special activation function in the last layer: the default activation function here is \"linear\", so the output of each neuron in this layer is just its input. \n",
    "\n",
    "In the next cell, we \"compile\" (i.e., build) the model, specifying stochastic gradient descent (`\"sgd\"`) as the means of minimizing the loss function.  However, TensorFlow/Keras does not have a negative log likelihood loss function, so this code uses a similar loss function, `SparseCategoricalCrossentropy`, which is designed for problems like this one where each input image should be put in a *unique* category (corresponding to the digit $0$, or $1$, etc., but not a combination of digits).  In other types of classification problem (e.g., images of clothing) an input could fall into multiple categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelK.compile(optimizer = \"sgd\",\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of `model.compile`, the line `metrics = [\"accuracy\"]` specifies that the accuracy of the network will be determined based on the fraction of images that are characterized correctly, as was done for the PyTorch model. \n",
    "\n",
    "Next, we train the model (for 15 epochs) on the training images & labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 9s 4ms/step - loss: 0.6410 - accuracy: 0.8286\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2953 - accuracy: 0.9159\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2446 - accuracy: 0.9302\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2114 - accuracy: 0.9400\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1862 - accuracy: 0.9474\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1664 - accuracy: 0.9530\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1506 - accuracy: 0.9574\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1369 - accuracy: 0.9614\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1258 - accuracy: 0.9647\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1162 - accuracy: 0.9676\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1074 - accuracy: 0.9695\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0992 - accuracy: 0.9717\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0935 - accuracy: 0.9735\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0871 - accuracy: 0.9755\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0822 - accuracy: 0.9768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x114f0a8bb20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelK.fit(train_images, train_labels, epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the model, we now can get its \"predictions\" for the labels of the test images.  To do that, we define a new \"probability\" model that's the same as the old model, except that the values from the output layer are converted to probabilities using the `.Softmax()` method.  We then run the `.predict()` method on that modified model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prob_model = tf.keras.Sequential([modelK, tf.keras.layers.Softmax()])   # outputs converted to probabilities\n",
    "predictions = prob_model.predict(test_images)                           # make predictions from probability model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the results, we can get the prediction for the first image and plot that image for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.99076748e-06, 5.00024669e-07, 1.45867001e-03, 2.68207095e-03,\n",
       "       1.69580872e-07, 2.46710970e-05, 2.24091745e-09, 9.95688558e-01,\n",
       "       1.75255536e-05, 1.21782505e-04], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig4, ax4 = plt.subplots(figsize=[3.5,2.5])\n",
    "plt.imshow(test_images[0], cmap = \"gray_r\")\n",
    "ax4.get_xaxis().set_visible(False)\n",
    "ax4.get_yaxis().set_visible(False)\n",
    "\n",
    "predictions[0]                                   # model's label for the depicted image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a bar chart of the output probabilies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 250x150 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "digits = range(0,10)                             # x-axis labels for bar chart\n",
    "fig5, ax5 = plt.subplots(figsize = [2.5, 1.5])\n",
    "ax5.bar(digits, predictions[0])\n",
    "plt.title(\"Probabilities of Image Matching the Digits 0-9\")\n",
    "ax5.axis([0,10,0,1])\n",
    "ax5.xaxis.set_major_locator(MultipleLocator(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model is easy.  We use the `model.evaluate()` function, supplying it with the test images & labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.1002 - accuracy: 0.9690 - 918ms/epoch - 3ms/step\n",
      "\n",
      "Test accuracy: 0.9690000\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = modelK.evaluate(test_images, test_labels, verbose = 2)\n",
    "\n",
    "print('\\nTest accuracy: %8.7f' %test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice -- we see that 97% (give or take) of the images have been classified properly, similar to the results with PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Saving and Loading a TensorFlow Model</font>\n",
    "\n",
    "To save a model created with TensorFlow/Keras, use the format \n",
    "\n",
    "```python\n",
    "model_name.save(\"PATH/filename\")```\n",
    "\n",
    "(The usual extension for a TensorFlow file is \".tf\".)\n",
    "\n",
    "For example, to save `modelK` (created in the highlighted cell above) in the same directory as this notebook, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./modelK.tf\\assets\n"
     ]
    }
   ],
   "source": [
    "modelK.save(\"./modelK.tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the TensorFlow/Keras model just saved, do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "modelK = keras.models.load_model(\"./modelK.tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Outline'>Back to the Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">16.4 Scikit-learn</font>\n",
    "\n",
    "(This section adapted from https://towardsdatascience.com/classifying-handwritten-digits-using-a-multilayer-perceptron-classifier-mlp-bc8453655880?gi=bee70f425cff .)\n",
    "\n",
    "In this section we follow the same basic procedure for MNIST digit recognition as with PyTorch and TensorFlow, but using the Python package ***`scikit-learn`*** (abbreviated ***`sklearn`*** in function calls), which is focused on machine learning approaches other than neural networks, but which does have a multi-layer perceptron model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages and load the images for display, then plot the first five images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load data and format for display\n",
    "mnist = fetch_openml('mnist_784', parser='auto')    # loads dataset\n",
    "images_to_show = mnist.data.to_numpy()              # formats images for display\n",
    "\n",
    "figure1 = plt.figure(figsize=[6, 6])\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow((images_to_show[i].reshape(28,28)), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, reload the images in a format suitable for a network to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "images, labels = fetch_openml(\"mnist_784\", version=1, parser='auto', return_X_y = True)\n",
    "\n",
    "images = images / 255.0       # Normalize intensity to range [0,1]\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the `print(X.shape)` statement shows that `X` contains 70,000 images, with 784 elements each, while the output of `print(y.shape)` indicates that `y` stores the digit labels.\n",
    "\n",
    "**Note:** It's critical to do the normalization `images = images / 255.0`, or else the loss function values will be much too large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the 70,000 images are separated into the training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train/test sets\n",
    "images_train = images[:60000]\n",
    "images_test = images[60000:]\n",
    "labels_train = labels[:60000]\n",
    "labels_test = labels[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we construct our model and specify its characteristics using the `MLPClassifier` function (see https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier for details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_background('#FFFF66')    # ignore this line\n",
    "\n",
    "modelS = MLPClassifier(\n",
    "    hidden_layer_sizes = (128, 64),\n",
    "    activation = \"relu\",     # ReLU activation function\n",
    "    max_iter = 100,\n",
    "    solver = \"sgd\",          # steepest gradient descent\n",
    "    verbose = True,          # whether to print progress messages\n",
    "    random_state = 1,        # initialization of weights & biases\n",
    "    learning_rate_init = 0.01,\n",
    "    tol = 0.02               # tolerance for loss function changes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply this model to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57104232\n",
      "Iteration 2, loss = 0.25275449\n",
      "Iteration 3, loss = 0.19993693\n",
      "Iteration 4, loss = 0.16566080\n",
      "Iteration 5, loss = 0.14162482\n",
      "Iteration 6, loss = 0.12271626\n",
      "Iteration 7, loss = 0.10799467\n",
      "Iteration 8, loss = 0.09708206\n",
      "Iteration 9, loss = 0.08668221\n",
      "Iteration 10, loss = 0.07910770\n",
      "Iteration 11, loss = 0.07199502\n",
      "Iteration 12, loss = 0.06582584\n",
      "Iteration 13, loss = 0.06049064\n",
      "Iteration 14, loss = 0.05553151\n",
      "Iteration 15, loss = 0.05109720\n",
      "Iteration 16, loss = 0.04729789\n",
      "Training loss did not improve more than tol=0.020000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(128, 64), learning_rate_init=0.01,\n",
       "              max_iter=100, random_state=1, solver=&#x27;sgd&#x27;, tol=0.02,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(128, 64), learning_rate_init=0.01,\n",
       "              max_iter=100, random_state=1, solver=&#x27;sgd&#x27;, tol=0.02,\n",
       "              verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(128, 64), learning_rate_init=0.01,\n",
       "              max_iter=100, random_state=1, solver='sgd', tol=0.02,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelS.fit(images_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988500\n",
      "Test set score: 0.974400\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: %f\" % modelS.score(images_train, labels_train))\n",
    "print(\"Test set score: %f\" % modelS.score(images_test, labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the network performs almost perfectly (98.85% correct) on the training set, and comparably to PyTorch's and TensorFlow's results for the test set (97.44% correct).  And these results were obtained with a relatively large value for `tol`, which controls when the training ends: that happens when the change in the loss function over 10 epochs is less than `tol`.  A smaller value for `tol` will result in more training epochs and better results.  (The value for `tol` was chosen so that the number of iterations would be similar to those used for PyTorch & TensorFlow.)\n",
    "\n",
    "It's worth noting that, although scikit-learn is more limited than PyTorch and TensorFlow in terms of its neural network functionality, it was easier to set up this digit classification problem than it was in PyTorch, and the training and test processes ran faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"blue\">Saving and Loading a scikit-learn Model</font>\n",
    "\n",
    "`scikit-learn` does not have its own functions to save and load network models; however, its models can be saved and loaded using a Python library called ***`pickle`***.  To save a model (with filename `modelS.pkl` in the directory where this notebook is), use  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./modelS.pkl\", 'wb') as file:\n",
    "    pickle.dump(modelS, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a model saved with the name `modelS.pkl`, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./modelS.pkl\", 'rb') as file:\n",
    "    pickle_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Outline'>Back to the Top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">**Recap**</font>\n",
    "\n",
    "* Neural networks can be powerful tools for solving a wide range of challenging computational problems.  Their great strength is that the algorithms they implement do not have to be programmed from scratch: networks can \"learn\" optimal designs for solving specific problems without detailed programmer guidance.  \n",
    "<br>\n",
    "\n",
    "* Implementing an effective neural network model to perform a specific task is part science, part art.  Moreover, entire texts have been written for both PyTorch and TensorFlow, so there's no way this module could cover all or even most of the important features of these systems without becoming unwieldy.  The purpose of this module is to give you an idea of how these systems (and scikit-lkearn) can be used to create a neural network model.\n",
    "<br>\n",
    "\n",
    "* Creating a neural network model involves some steps that are common to the packages above and some that are unique to each package.  One common step is the loading, and possibly modification, of the training and test data.  The different packages also all include a function that implements the model definition, specifying the number and size of layers, and their activation functions: for PyTorch that function is `torch.nn.Sequential`, for TensorFlow it's `TensorFlow.keras.Sequential`, and for scikit-learn it's `sklearn.neural_network.MLPClassifier` (for a multi-layer perceptron network).  PyTorch then requires multiple steps executed in a loop over epochs and inputs to train a model, while TensorFlow uses just its `.compile()` and `.fit()` functions to do that, and scikit-learn needs only its `.fit()` method.  For testing a model, PyTorch again requires a loop with multiple steps, while TensorFlow does it with the `.evaluate()` method and scikit-learn uses the `classifier.score()` function.\n",
    "<br>\n",
    "\n",
    "* The best way to create a network for a new task is to find one for a similar task that already has been created, on the internet or in a textbook, and then modify it for your particular needs.  There are general approaches that have been found to work better for specific applications, so it makes sense to start with one of those models.  And, as usual with computing challenges, you often can find answers to questions that arise when constructing a model by searching on the internet for explanations of error messages or suggestions on approaches to take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Reflection Prompts</font>\n",
    "\n",
    "These questions are intended to help you think about what you learned from this module and how it might be useful to you in the future. You are strongly encouraged to answer them before moving on to the next module.  \n",
    "\n",
    "- Which components of this module did you find you were easily able to work through, and why do you think they were especially easy for you?\n",
    "\n",
    "- Which components of this module did you find more difficult to work through, and why do you think they were challenging?\n",
    "\n",
    "- When you got stuck, what did you do to get unstuck? Could this or similar actions be helpful if you get stuck in future work?\n",
    "\n",
    "- What do you understand more deeply about this material?\n",
    "\n",
    "- What questions or uncertainties remain for you regarding this material?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Exercises</font> \n",
    "\n",
    "#### <u>Exercise #1</u>\n",
    "\n",
    "The Machine Learning module analyzed the NIST handwritten digit dataset.  Another well-known image dataset used for evaluating neural networks for categorization is the \"Fashion MNIST\" set of items of clothing categorized into nine types, each with an associated numerical label: \n",
    "\n",
    "0 :: T-shirt/top  \n",
    "1 :: Trouser  \n",
    "2 :: Pullover  \n",
    "3 :: Dress  \n",
    "4 :: Coat  \n",
    "5 :: Sandal  \n",
    "6 :: Shirt  \n",
    "7 :: Sneaker  \n",
    "8 :: Bag  \n",
    "9 :: Ankle boot  \n",
    "\n",
    "Like the original NIST digit dataset, this one is divided into a training set of 60,000 images and a test set of 10,000 images, where each image is 28 x 28 pixels.  Those sets, together with files containing the corresponding labels, can be downloaded from here: https://github.com/zalandoresearch/fashion-mnist/tree/master/data/fashion .  Clicking on the four links on that page will take you to four pages where you can download the files.  (The files labeled with \"t10k\" are for the test data.) The files are in \"zipped\" format, and must be unzipped before they can be loaded into a notebook. (The free Windows utilities 7-zip or WinZip, or the built-in zip/unzip utility on Macs, should do the job.)  \n",
    "\n",
    "Alternatively, if you construct your network using Pytorch, you should be able to get the dataset using the same approach as in the module, but with the two occurrences there of `datasets.MNIST` replaced by `datasets.FashionMNIST`.  If you use TensorFlow to build your network, you should be able to get the dataset using the module's approach but replacing `mnist.load_data` with `fashion_mnist.load_data`.  If you use `scikit-learn` to design your network, the files can be fetched from the openml repository (https://www.openml.org/search?type=data&status=active) using the same syntax as the example in the module, but with `fashion-mnist` replacing `mnist_784`.\n",
    "\n",
    "**(a)** Load the training and test images into a notebook and display the first five training images to get a sense of what the images in the set look like.  \n",
    "\n",
    "**(b)** Using one of the packages presented in the Machine Learning module, construct a neural network to categorize the images in the Fashion MNIST training dataset and test it on the test dataset.  Note that this clothing dataset is more challenging to categorize than the handwritten digit dataset since the images are not as simple or distinct as the digits, so it might take some trial and error to get good network parameters.  Vary the number of hidden layers and/or the \"solver\" (try something other than steepest gradient descent) and/or the activation function and/or other adjustable parameters available in whatever package you use to get the **test** set score above 0.88 or 88%.  You may need to consult the documentation for your package to identify the parameter options; see the links in the Machine Learning module or just search online.\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "### !!! <u>Capstone Python Programming Exercise</u> !!! \n",
    "As a final programming challenge if you have time (and courage!), try coding up a neural network *from scratch.*  You probably will want to take an object-oriented approach by creating a `neuron` class with an activation function as a method and connections as attributes (see Module 14).  Test your network on the handwritten digit dataset.  Good luck!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Breakpoint Answers</font>\n",
    "\n",
    "\n",
    "**Breakpoint 1:** \n",
    "$$S'(x) = \\frac{e^{-x}}{(1 + e^{-x})^2} = S(x) \\left( \\frac{e^{-x}}{1 + e^{-x}} \\right) = S(x) \\left( \\frac{1 + e^{-x}}{1 + e^{-x}} - \\frac{1}{1 + e^{-x}} \\right) = S(x) [1 - S(x)].$$.\n",
    "\n",
    " \n",
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
